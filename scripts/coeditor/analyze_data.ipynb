{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from coeditor.common import *\n",
    "from coeditor.dataset import *\n",
    "from coeditor.encoding import *\n",
    "from spot.utils import pretty_print_dict\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = WindowArgs(4096)\n",
    "cst_encoder = CstBasedEditEncoder(window)\n",
    "encoder = AnalysisBasedEditEncoder(window, extra_ctx_min_size=1000)\n",
    "# data = dataset_from_projects([proj_root()], encoder, max_history_per_repo=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"SPOT\"\n",
    "dataset_name = \"medium\"\n",
    "window = WindowArgs(4096)\n",
    "encoder = AnalysisBasedEditEncoder(\n",
    "    window=window, extra_ctx_min_size=1000, extra_ctx_names=(\"usees\", \"post-usees\")\n",
    ")\n",
    "save_dir = get_dataset_dir(dataset_name) / \"tokenized-file_collapsed\"# repr_modified_args(encoder)\n",
    "datasets = load_datasets(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n",
      "n_projects: 20\n",
      "n_edits: 12666\n",
      "input_size:\n",
      "   mean: 1838.3\n",
      "   median: 1537.5\n",
      "   min: 15\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 113.59\n",
      "   median: 75\n",
      "   min: 5\n",
      "   max: 4776\n",
      "==================== valid ====================\n",
      "n_projects: 10\n",
      "n_edits: 2297\n",
      "input_size:\n",
      "   mean: 1770.5\n",
      "   median: 1541\n",
      "   min: 19\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 116.91\n",
      "   median: 89\n",
      "   min: 5\n",
      "   max: 1567\n",
      "==================== train ====================\n",
      "n_projects: 100\n",
      "n_edits: 50804\n",
      "input_size:\n",
      "   mean: 1819.5\n",
      "   median: 1489\n",
      "   min: 19\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 97.962\n",
      "   median: 64\n",
      "   min: 5\n",
      "   max: 8434\n"
     ]
    }
   ],
   "source": [
    "for group, dataset in datasets.items():\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    pretty_print_dict(dataset.overall_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n",
      "n_projects: 20\n",
      "n_edits: 12667\n",
      "input_size:\n",
      "   mean: 1773.5\n",
      "   median: 1648\n",
      "   min: 19\n",
      "   max: 4102\n",
      "output_size:\n",
      "   mean: 113.57\n",
      "   median: 75\n",
      "   min: 5\n",
      "   max: 4776\n",
      "==================== valid ====================\n",
      "n_projects: 10\n",
      "n_edits: 2297\n",
      "input_size:\n",
      "   mean: 1702.5\n",
      "   median: 1559\n",
      "   min: 23\n",
      "   max: 4102\n",
      "output_size:\n",
      "   mean: 116.91\n",
      "   median: 89\n",
      "   min: 5\n",
      "   max: 1567\n",
      "==================== train ====================\n",
      "n_projects: 100\n",
      "n_edits: 50792\n",
      "input_size:\n",
      "   mean: 1700.8\n",
      "   median: 1559\n",
      "   min: 23\n",
      "   max: 4102\n",
      "output_size:\n",
      "   mean: 97.974\n",
      "   median: 64\n",
      "   min: 5\n",
      "   max: 8434\n"
     ]
    }
   ],
   "source": [
    "for group, dataset in datasets.items():\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    pretty_print_dict(dataset.overall_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All edits: 1331\n",
      "All edits with extra context: 360\n"
     ]
    }
   ],
   "source": [
    "with_ctx = [e for e in data.all_edits() if decode_tokens(AnalysisBasedEditEncoder.CtxSepTokens) in decode_tokens(e.input_tks)]\n",
    "\n",
    "print(\"All edits:\", len(data.all_edits()))\n",
    "print(\"All edits with extra context:\", len(with_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Left Context========\n",
      "\n",
      "class UsageAnalysis:\n",
      " <add>     def __init__(self, project: PythonProject, add_override_usages: bool):\n",
      " <del>     def __init__(self, project: PythonProject):\n",
      "        self.project = project\n",
      " <add>         self.add_override_usages = add_override_usages\n",
      "        self.ns_hier = ModuleHierarchy.from_modules(project.modules.keys())\n",
      "        module2ns = build_project_namespaces(project)\n",
      "        self.sorted_modules = list(module2ns.keys())\n",
      "\n",
      "        self.path2elem = {v.path: v for v in project.all_elems()}\n",
      "        self.path2class = {\n",
      "            cls.path: cls\n",
      "            for mod in project.modules.values()\n",
      "            for cls in mod.all_classes()\n",
      "        }\n",
      "\n",
      "        for mname, ns in module2ns.items():\n",
      "            for s, p in ns.items():\n",
      "                if p in self.path2class:\n",
      "                    cls = self.path2class[p]\n",
      "                    self.path2class.setdefault(ProjectPath(mname, s), cls)\n",
      "                elif p in self.path2elem:\n",
      "                    self.path2elem.setdefault(ProjectPath(mname, s), self.path2elem[p])\n",
      "\n",
      "        self.mod2analysis = {\n",
      "            mname: ModuleAnlaysis(project.modules[mname])\n",
      "            for mname in self.sorted_modules\n",
      "        }\n",
      "        for ma in self.mod2analysis.values():\n",
      "            ma.udpate_superclasses_()\n",
      "\n",
      "        self.cls2members = cls2members = dict[ProjectPath, dict[str, PythonElem]]()\n",
      " <add>         all_usages = list[ProjectUsage]()\n",
      "\n",
      "        def process_cls(cls: PythonClass):\n",
      "            if (cpath := cls.path) in cls2members:\n",
      "                return\n",
      "            members = cls2members[cpath] = dict[str, PythonElem]()\n",
      "            bases = not_none(cls.superclasses)\n",
      "            parents = [\n",
      "                x for p in bases if (x := self.find_class(cpath.module, p)) is not None\n",
      "            ]\n",
      "            for parent in parents:\n",
      "                process_cls(parent)\n",
      "                members.update(cls2members[parent.path])\n",
      "            for a in cls.attributes.values():\n",
      " <add>                 if self.add_override_usages and a.name in members:\n",
      " <add>                     all_usages.append(ProjectUsage(a.path, members[a.name].path, True))\n",
      "                members[a.name] = a\n",
      "            for m in cls.methods.values():\n",
      " <add>                 if self.add_override_usages and m.name in members:\n",
      " <add>                     all_usages.append(ProjectUsage(m.path, members[m.name].path, True))\n",
      "                members[m.name] = m\n",
      "            for name, el in members.items():\n",
      "                self.path2elem[cpath.append(name)] = el\n",
      "\n",
      "        for mname in self.sorted_modules:\n",
      "            for cls in project.modules[mname].all_classes():\n",
      "                process_cls(cls)\n",
      "\n",
      "        all_class_members = {x.path for x in project.all_elems() if x.in_class}\n",
      "        self.name2class_member = groupby(\n",
      "            [self.path2elem[p] for p in all_class_members], lambda e: e.name\n",
      "        )\n",
      "\n",
      "        all_fixtures = [f for f in project.all_funcs() if f.is_fixture]\n",
      "        name2fixtures = groupby(all_fixtures, lambda f: f.name)\n",
      "        self.name2fixtures = {\n",
      "            n: {f.path for f in fs} for n, fs in name2fixtures.items()\n",
      "        }\n",
      "\n",
      " <add>         for mname, ma in self.mod2analysis.items():\n",
      " <add>             for caller, span, qname, is_call in ma.compute_module_usages():\n",
      " <add>                 all_usages.extend(self.generate_usages(mname, caller, qname, is_call))\n",
      " <add> \n",
      "        best_usages = dict[tuple[ProjectPath, ProjectPath], ProjectUsage]()\n",
      " <add>         for u in all_usages:\n",
      " <add>             up = u.user, u.used\n",
      " <add>             if up not in best_usages or u.is_certain > best_usages[up].is_certain:\n",
      " <add>                 best_usages[up] = u\n",
      " <add> \n",
      " <del>         for mname, ma in self.mod2analysis.items():\n",
      " <del>             usages = ma.compute_module_usages()\n",
      " <del>             for caller, span, qname, is_call in usages:\n",
      " <del>                 for u in self.generate_usages(mname, caller, span, qname, is_call):\n",
      " <del>                     up = u.user, u.used\n",
      " <del>                     if (\n",
      " <del>                         up not in best_usages\n",
      " <del>                         or u.is_certain > best_usages[up].is_certain\n",
      " <del>                     ):\n",
      " <del>                         best_usages[up] = u\n",
      "        all_usages = list(best_usages.values())\n",
      "        self.all_usages = all_usages\n",
      "        self.user2used = groupby(all_usages, lambda u: u.user)\n",
      "        self.used2user = groupby(all_usages, lambda u: u.used)\n",
      "\n",
      " <add>     add_override_usages:...\n",
      "\n",
      "@dataclass\n",
      "class PreprocessArgs:\n",
      " <add>     add_override_usages: bool = False\n",
      "# Usees ends\n",
      "def dataset_from_repos(\n",
      "    repos_root: Path,\n",
      "    repos_paths: Iterable[Path],\n",
      "    pre_args: PreprocessArgs,\n",
      "    max_line_width: int = 400,\n",
      "    max_workers: int | None = None,\n",
      "    tqdm_args: dict = {},\n",
      ") -> \"TokenizedSrcSet\":...\n",
      "\n",
      "def mk_preamble(\n",
      "    mod: cst.Module,\n",
      "    pre_args: PreprocessArgs,\n",
      ") -> tuple[str, TokenSeq]:...\n",
      "\n",
      "def wrap_main_code(code: str) -> str:...\n",
      "\n",
      "def data_project_from_dir(\n",
      "    root: Path,\n",
      "    max_line_width: int = 400,\n",
      "    drop_comments: bool = True,\n",
      "    file_filter: Callable[[Path], bool] = lambda p: True,\n",
      ") -> PythonProject:...\n",
      "\n",
      "# EDIT:\n",
      "\n",
      "========Ground Truth========\n",
      " <8>:<add>     analysis = UsageAnalysis(proj, pre_args.add_override_usages)\n",
      "     <del>     analysis = UsageAnalysis(proj)\n",
      "\n",
      "========Main Code========\n",
      " <0>def repo_to_tk_srcs(\n",
      " <1>    repo: Path,\n",
      " <2>    pre_args: PreprocessArgs,\n",
      " <3>    max_line_width: int = 400,\n",
      " <4>) -> list[TokenizedSrc]:\n",
      " <5>    proj = data_project_from_dir(\n",
      " <6>        repo, max_line_width=max_line_width, drop_comments=pre_args.drop_comments\n",
      " <7>    )\n",
      " <8>    analysis = UsageAnalysis(proj)\n",
      " <9>    sorted_moduels = analysis.sorted_modules\n",
      "<10>\n",
      "<11>    srcs = list[TokenizedSrc]()\n",
      "<12>    for mpath in sorted_moduels:\n",
      "<13>        mod = proj.modules[mpath]\n",
      "<14>        preamble, tokenized_preamble = mk_preamble(mod.tree, pre_args)\n",
      "<15>\n",
      "<16>        signature_map = dict() if pre_args.drop_env_types else None\n",
      "<17>        for elem in mod.all_elements():\n",
      "<18>            main_m = cst.Module(\n",
      "<19>                reformat_elems([elem], analysis.path2class, None, keep_body_types=True)\n",
      "<20>            )\n",
      "<21>            annots_info, types = collect_user_annotations(main_m)\n",
      "<22>            if len(annots_info) == 0:\n",
      "<23>                continue\n",
      "<24>            for info in annots_info:\n",
      "<25>                info.annot_range = None\n",
      "<26>            types_str = [\n",
      "<27>                main_m.code_for_node(not_none(info.annot).annotation)\n",
      "<28>                for info in annots_info\n",
      "<29>            ]\n",
      "<30>            mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "<31>            replaces = dict()\n",
      "<32>            for info in annots_info:\n",
      "<33>                replaces[info.path] = mask_annot\n",
      "<34>            new_code = wrap_main_code(apply_annotations(main_m, replaces).code)\n",
      "<35>            code_segs = new_code.split(SpecialNames.TypeMask)\n",
      "<36>            assert (\n",
      "<37>                len(code_segs) == len(types) + 1\n",
      "<38>            ), f\"{len(code_segs)}!= {len(types) + 1}. replaces: {replaces}\\ncode: {new_code}\"\n",
      "<39>\n",
      "<40>            left_m, right_m = ctx_modules_for_elem(\n",
      "<41>                elem, analysis, pre_args, signature_map\n",
      "<42>            )\n",
      "<43>            left_tks = None\n",
      "<44>            if left_m is not None:\n",
      "<45>                left_tks = DefaultTokenizer.encode(\n",
      "<46>                    left_m.code, add_special_tokens=False\n",
      "<47>                )\n",
      "<48>            right_tks = None\n",
      "<49>            if right_m is not None:\n",
      "<50>                right_tks = DefaultTokenizer.encode(\n",
      "<51>                    right_m.code, add_special_tokens=False\n",
      "<52>                )\n",
      "<53>\n",
      "<54>            file = proj.root_dir / proj.module2src_file[mpath] / elem.path.path\n",
      "<55>            src = tokenized_src_from_segs(\n",
      "<56>                file=file,\n",
      "<57>                repo=repo,\n",
      "<58>                preamble=preamble,\n",
      "<59>                tokenized_preamble=tokenized_preamble,\n",
      "<60>                code_segs=code_segs,\n",
      "<61>                types=types,\n",
      "<62>                types_str=types_str,\n",
      "<63>                annots_info=annots_info,\n",
      "<64>                cst_code=main_m.code,\n",
      "<65>                left_extra_tks=left_tks,\n",
      "<66>                right_extra_tks=right_tks,\n",
      "<67>            )\n",
      "<68>            srcs.append(src)\n",
      "<69>\n",
      "<70>    return srcs\n",
      "<71>\n",
      "========Right Context========\n",
      "\n",
      "def ctx_modules_for_elem(\n",
      "    elem: PythonElem,\n",
      "    analysis: UsageAnalysis,\n",
      "    pre_args: PreprocessArgs,\n",
      "    signature_map: SignatureMap | None,\n",
      ") -> tuple[cst.Module | None, cst.Module | None]:...\n",
      "\n",
      "def reformat_elems(\n",
      "    elems: Sequence[PythonElem],\n",
      "    path2class: dict[ProjectPath, PythonClass],\n",
      "    signature_map: SignatureMap | None,\n",
      "    reversed: bool = False,\n",
      "    signature_only=False,\n",
      "    keep_body_types=False,\n",
      "):...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(with_ctx[4].show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"medium\"\n",
    "save_dir = get_dataset_dir(dataset_name) / \"tokenized-file_collapsed\"\n",
    "datasets = load_datasets(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n",
      "n_projects: 20\n",
      "n_edits: 12666\n",
      "input_size:\n",
      "   mean: 1838.3\n",
      "   median: 1537.5\n",
      "   min: 15\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 113.59\n",
      "   median: 75\n",
      "   min: 5\n",
      "   max: 4776\n",
      "==================== valid ====================\n",
      "n_projects: 10\n",
      "n_edits: 2297\n",
      "input_size:\n",
      "   mean: 1770.5\n",
      "   median: 1541\n",
      "   min: 19\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 116.91\n",
      "   median: 89\n",
      "   min: 5\n",
      "   max: 1567\n",
      "==================== train ====================\n",
      "n_projects: 100\n",
      "n_edits: 50804\n",
      "input_size:\n",
      "   mean: 1819.5\n",
      "   median: 1489\n",
      "   min: 19\n",
      "   max: 4096\n",
      "output_size:\n",
      "   mean: 97.962\n",
      "   median: 64\n",
      "   min: 5\n",
      "   max: 8434\n"
     ]
    }
   ],
   "source": [
    "for group, dataset in datasets.items():\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    pretty_print_dict(dataset.overall_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in datasets:\n",
    "    if not (save_dir / f\"{group}.pkl\").exists():\n",
    "        continue\n",
    "    dataset = pickle_load(save_dir / f\"{group}.pkl\")\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    display(dataset.per_repo_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(datasets[\"test\"].all_edits())[1].show_prediction())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
