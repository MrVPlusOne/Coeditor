{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from coeditor.common import *\n",
    "from coeditor.dataset import *\n",
    "from coeditor.encoding import *\n",
    "from coeditor.encoders import BasicQueryEditEncoder\n",
    "\n",
    "from spot.utils import pretty_print_dict\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting commit histories: 100%|██████████| 1/1 [00:01<00:00,  1.47s/repo]\n",
      "Create tokenized edits: 100%|██████████| 1/1 [00:03<00:00,  3.38s/chunk]\n"
     ]
    }
   ],
   "source": [
    "# test_data_name = \"medium\"\n",
    "# test_data_name = \"SPOT\"\n",
    "test_data_name = \"small\"\n",
    "# encoder = AnalysisBasedEditEncoder(extra_ctx_names=(\"usees\", \"post-usees\"), add_truncate_bos=False)\n",
    "# encoder = CstBasedEditEncoder(500, add_truncate_bos=False)\n",
    "encoder = BasicQueryEditEncoder(add_truncate_bos=False)\n",
    "data = dataset_from_projects([proj_root()], encoder, [False], max_history_per_repo=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_projects: 1\n",
      "n_edits: 49\n",
      "n_additions: 49\n",
      "input_tks:\n",
      "   mean: 138.39\n",
      "   median: 117\n",
      "   min: 27\n",
      "   max: 386\n",
      "output_tks:\n",
      "   mean: 59.653\n",
      "   median: 39\n",
      "   min: 12\n",
      "   max: 256\n",
      "references:\n",
      "   mean: 46.551\n",
      "   median: 47\n",
      "   min: 2\n",
      "   max: 94\n",
      "ref_size_sum:\n",
      "   mean: 4500.5\n",
      "   median: 4259\n",
      "   min: 335\n",
      "   max: 6810\n"
     ]
    }
   ],
   "source": [
    "pretty_print_dict(data.overall_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_references: 47\n",
      "========Ground Truth========\n",
      " <1>:<add>         self._record_annot(node.returns)\n",
      "     <del>         self.annotations[self._current_path()] = node.returns\n",
      "\n",
      "========Main Code========\n",
      "# path: spot.type_checking/AnnotCollector.visit_FunctionDef\n",
      "\n",
      "class AnnotCollector(cst.CSTVisitor):\n",
      "    def visit_FunctionDef(self, node: cst.FunctionDef):\n",
      " <0>        self.stack.append(SpecialNames.Return)\n",
      " <1>        self.annotations[self._current_path()] = node.returns\n",
      " <2>        self.stack.pop()\n",
      " <3>\n",
      "===========ref: data.code.env_code_1/fib===========\n",
      "<s> <add> # data.code.env_code_1/fib\n",
      " <add> def fib(n):\n",
      " <add>     if n == 0:\n",
      " <add>         return 0\n",
      " <add>     elif n == 1:\n",
      " <add>         return 1\n",
      " <add>     else:\n",
      " <add>         return fib(n-1) + fib(n-2)</s>\n",
      "===========ref: data.code.env_code_1/foo===========\n",
      "<s> <add> # data.code.env_code_1/foo\n",
      " <add> def foo(bar):\n",
      " <add>     return bar</s>\n",
      "===========ref: data.code.env_code_1/int_add===========\n",
      "<s> <add> # data.code.env_code_1/int_add\n",
      " <add> def int_add(a, b):\n",
      " <add>     return a + b</s>\n",
      "===========ref: data.code.env_code_1/int_tripple_add===========\n",
      "<s> <add> # data.code.env_code_1/int_tripple_add\n",
      " <add> def int_tripple_add(a, b, c):\n",
      " <add>     return a + b + c</s>\n",
      "===========ref: spot.type_checking/AnnotPath.__repr__===========\n",
      "<s> <add> # spot.type_checking/AnnotPath.__repr__\n",
      " <add> def __repr__(self):\n",
      " <add>     return f\"AnnotPath('{'.'.join(self.value)}')\"</s>\n",
      "===========ref: spot.type_checking/AnnotPath.__str__===========\n",
      "<s> <add> # spot.type_checking/AnnotPath.__str__\n",
      " <add> def __str__(self):\n",
      " <add>     return f\"'{'.'.join(self.value)}'\"</s>\n",
      "===========ref: spot.type_checking/AnnotCollector.annot_paths===========\n",
      "<s> <add> # spot.type_checking/AnnotCollector.annot_paths\n",
      " <add> annot_paths:...</s>\n",
      "===========ref: spot.type_checking/AnnotCollector._record_annot===========\n",
      "<s> <add> # spot.type_checking/AnnotCollector._record_annot\n",
      " <add> def _record_annot(self, annot: Union[cst.Annotation, None]):\n",
      " <add>     path = self._current_path()\n",
      " <add>     self.annot_paths.append(path)\n",
      " <add>     if annot is not None:\n",
      " <add>         self.annotations[path] = annot</s>\n",
      "===========ref: spot.type_checking/MypyChecker.close===========\n",
      "<s> <add> # spot.type_checking/MypyChecker.close\n",
      " <add> def close(self):\n",
      " <add>     subprocess.run(\n",
      " <add>         [\"python\", self.dmypy_path, \"stop\"],\n",
      " <add>         cwd=self.code_dir,\n",
      " <add>     )</s>\n",
      "===========ref: spot.type_checking/MypyChecker.check_code_dir===========\n",
      "<s> <add> # spot.type_checking/MypyChecker.check_code_dir\n",
      " <add> def check_code_dir(self) -> MypyResult:\n",
      " <add>     return self._run_mypy([\"python\", self.dmypy_path, \"check\", self.code_dir])</s>\n",
      "===========ref: spot.type_checking/MypyChecker.recheck_files===========\n",
      "<s> <add> # spot.type_checking/MypyChecker.recheck_files\n",
      " <add> def recheck_files(self, *updated_files: str) -> MypyResult:\n",
      " <add>     return self._run_mypy([\"python\", self.dmypy_path, \"recheck\", \"--update\", *updated_files])\n",
      " <add> </s>\n",
      "===========ref: spot.type_checking/MypyChecker._run_mypy===========\n",
      "<s> <add> # spot.type_checking/MypyChecker._run_mypy\n",
      " <add> def _run_mypy(self, cmd: list[str]) -> MypyResult:\n",
      " <add>     result = subprocess.run(\n",
      " <add>         cmd,\n",
      " <add>         capture_output=True,\n",
      " <add>         text=True,\n",
      " <add>         cwd=self.code_dir,\n",
      " <add>     )\n",
      " <add>     lines = result.stdout.splitlines()\n",
      " <add>     assert (\n",
      " <add>         len(lines) > 0\n",
      " <add>     ), f\"mypy failed. Command: `{' '.join(cmd)}`\\nError: {result.stderr}\"\n",
      " <add>     num_error_dict: dict[str, int] = {}\n",
      " <add>     for l in lines:\n",
      " <add>         m = re.match(r\"(.*\\.py):\\d+: error:.+\", l)\n",
      " <add>         if m is not None:\n",
      " <add>             num_error_dict[m.group(1)] = num_error_dict.get(m.group(1), 0) + 1\n",
      " <add> \n",
      " <add>     m = re.match(r\"Found (\\d+) errors? in\", lines[-1])\n",
      " <add>     if m is None:\n",
      " <add>         num_errors = 0\n",
      " <add>     else:\n",
      " <add>         num_errors = int(m.group(1))\n",
      " <add> \n",
      " <add>     total_errors = sum(num_error_dict.values())\n",
      " <add>     assert (\n",
      " <add>         num_errors == total_errors\n",
      " <add>     ), f\"{num_errors}!= {total_errors}. mypy output: {result.stdout}\"\n",
      " <add>     return MypyResult(num_errors, num_error_dict, result.stdout)</s>\n",
      "===========ref: spot.type_checking/mypy_checker.dmypy_path===========\n",
      "<s> <add> # spot.type_checking/mypy_checker.dmypy_path\n",
      " <add> dmypy_path: str</s>\n",
      "===========ref: spot.type_checking/mypy_checker.code_dir===========\n",
      "<s> <add> # spot.type_checking/mypy_checker.code_dir\n",
      " <add> code_dir: str</s>\n",
      "===========ref: spot.type_checking/mypy_checker.__enter__===========\n",
      "<s> <add> # spot.type_checking/mypy_checker.__enter__\n",
      " <add> def __enter__(self):\n",
      " <add>     self.checker = MypyChecker(self.dmypy_path, self.code_dir)\n",
      " <add>     return self.checker</s>\n",
      "===========ref: spot.type_checking/mypy_checker.checker===========\n",
      "<s> <add> # spot.type_checking/mypy_checker.checker\n",
      " <add> checker:...</s>\n",
      "===========ref: spot.type_checking/mypy_checker.__exit__===========\n",
      "<s> <add> # spot.type_checking/mypy_checker.__exit__\n",
      " <add> def __exit__(self, exc_type, exc_val, exc_tb):\n",
      " <add>     self.checker.close()</s>\n",
      "===========ref: spot.type_checking/MypyChecker.mypy_version===========\n",
      "<s> <del> # spot.type_checking/MypyChecker.mypy_version\n",
      " <del> mypy_version:...</s>\n",
      "===========ref: spot.type_checking/MypyChecker.stop_daemon===========\n",
      "<s> <del> # spot.type_checking/MypyChecker.stop_daemon\n",
      " <del> def stop_daemon(self):\n",
      " <del>     subprocess.run(\n",
      " <del>         [\"python\", self.dmypy_path, \"stop\"],\n",
      " <del>         cwd=self.code_dir,\n",
      " <del>     )</s>\n",
      "===========ref: spot.type_checking/MypyChecker.__del__===========\n",
      "<s> <del> # spot.type_checking/MypyChecker.__del__\n",
      " <del> def __del__(self):\n",
      " <del>     self.stop_daemon()</s>\n",
      "===========ref: spot.type_checking/MypyChecker.check_file===========\n",
      "<s> <del> # spot.type_checking/MypyChecker.check_file\n",
      " <del> def check_file(self, fpath):\n",
      " <del>     print(\"chekcing!\")\n",
      " <del>     cmd = [\"python\", self.dmypy_path, \"run\", \"--\", fpath]\n",
      " <del>     result = subprocess.run(\n",
      " <del>         cmd,\n",
      " <del>         capture_output=True,\n",
      " <del>         text=True,\n",
      " <del>         cwd=self.code_dir,\n",
      " <del>     )\n",
      " <del>     lines = result.stdout.splitlines()\n",
      " <del>     assert len(lines) > 0, f\"mypy failed. Error: {result.stderr}\"\n",
      " <del>     num_error_dict = {}\n",
      " <del>     for l in lines:\n",
      " <del>         m = re.match(r\"(.*\\.py):\\d+: error:.+\", l)\n",
      " <del>         if m is not None:\n",
      " <del>             num_error_dict[m.group(1)] = num_error_dict.get(m.group(1), 0) + 1\n",
      " <del> \n",
      " <del>     m = re.match(r\"Found (\\d+) errors? in\", lines[-1])\n",
      " <del>     if m is None:\n",
      " <del>         num_errors = 0\n",
      " <del>     else:\n",
      " <del>         num_errors = int(m.group(1))\n",
      " <del> \n",
      " <del>     total_errors = sum(num_error_dict.values())\n",
      " <del>     assert (\n",
      " <del>         num_errors == total_errors\n",
      " <del>     ), f\"{num_errors}!= {total_errors}. mypy output: {result.stdout}\"\n",
      " <del>     return MypyResult(num_errors, num_error_dict, result.stdout)</s>\n",
      "===========ref: spot.type_checking/AnnotCollector.visit_AnnAssign===========\n",
      "<s># spot.type_checking/AnnotCollector.visit_AnnAssign\n",
      " <add> def visit_AnnAssign(self, node: cst.AnnAssign):\n",
      " <add>     self._record_annot(node.annotation)\n",
      " <del> def visit_AnnAssign(self, ndoe: cst.AnnAssign):\n",
      " <del>     self.annotations[self._current_path()] = ndoe.annotation</s>\n",
      "===========ref: spot.type_checking/apply_annotations===========\n",
      "<s># spot.type_checking/apply_annotations\n",
      " <add> def apply_annotations(code: cst.CSTNode, annots: dict[AnnotPath, cst.Annotation]):\n",
      " <del> def apply_annotations(code: cst.CSTNode, annots: Dict[AnnotPath, cst.Annotation]):\n",
      "    applier = AnnotApplier(annots)\n",
      "    return code.visit(applier)</s>\n",
      "===========ref: spot.type_checking/MypyChecker.__init__===========\n",
      "<s># spot.type_checking/MypyChecker.__init__\n",
      "def __init__(self, dmypy_path, code_dir) -> None:\n",
      "    self.code_dir = realpath(code_dir)\n",
      "    self.dmypy_path = realpath(dmypy_path)\n",
      " <add>     subprocess.run(\n",
      " <add>         [\n",
      " <add>             \"python\",\n",
      " <add>             self.dmypy_path,\n",
      " <add>             \"start\",\n",
      " <add>             \"--\",\n",
      " <add>             \"--follow-imports=skip\",\n",
      " <add>         ],\n",
      " <add>         cwd=self.code_dir,\n",
      " <add>     )\n",
      " <add>     subprocess.run(\n",
      " <add>         [\"python\", self.dmypy_path, \"check\", self.code_dir],\n",
      " <add>         cwd=self.code_dir,\n",
      " <del>     self.mypy_version = subprocess.run(\n",
      " <del>         [\"python\", self.dmypy_path, \"-V\"],\n",
      "        capture_output=True,\n",
      " <add>     )\n",
      " <del>         text=True,\n",
      " <del>         cwd=self.code_dir,\n",
      " <del>     ).stdout</s>\n",
      "===========ref: spot.type_checking/collect_annotations===========\n",
      "<s># spot.type_checking/collect_annotations\n",
      " <add> def collect_annotations(\n",
      " <add>     code: cst.CSTNode,\n",
      " <add> ) -> Tuple[list[AnnotPath], dict[AnnotPath, cst.Annotation]]:\n",
      " <del> def collect_annotations(code: cst.CSTNode) -> Dict[AnnotPath, Optional[cst.Annotation]]:\n",
      "    collector = AnnotCollector()\n",
      "    code.visit(collector)\n",
      " <add>     return collector.annot_paths, collector.annotations\n",
      " <del>     return collector.annotations</s>\n",
      "===========ref: spot.type_checking/AnnotCollector.visit_Param===========\n",
      "<s># spot.type_checking/AnnotCollector.visit_Param\n",
      "def visit_Param(self, node: cst.Param):\n",
      " <add>     self._record_annot(node.annotation)\n",
      " <del>     self.annotations[self._current_path()] = node.annotation</s>\n",
      "===========ref: spot.type_checking/AnnotCollector.__init__===========\n",
      "<s># spot.type_checking/AnnotCollector.__init__\n",
      "def __init__(self):\n",
      "    self.stack: List[str] = []\n",
      " <add>     self.annot_paths: List[AnnotPath] = []\n",
      " <add>     self.annotations: Dict[AnnotPath, cst.Annotation] = {}\n",
      " <del>     self.annotations: Dict[AnnotPath, Optional[cst.Annotation]] = {}</s>\n",
      "===========ref: spot.type_inference/TypeExpr===========\n",
      "<s> <add> # spot.type_inference/TypeExpr\n",
      " <add> TypeExpr = cst.BaseExpression</s>\n",
      "===========ref: spot.type_inference/TypeInfState.module===========\n",
      "<s> <add> # spot.type_inference/TypeInfState.module\n",
      " <add> module: cst.Module</s>\n",
      "===========ref: spot.type_inference/TypeInfState.to_annot===========\n",
      "<s> <add> # spot.type_inference/TypeInfState.to_annot\n",
      " <add> to_annot: list[AnnotPath]</s>\n",
      "===========ref: spot.type_inference/TypeInfState.annotated===========\n",
      "<s> <add> # spot.type_inference/TypeInfState.annotated\n",
      " <add> annotated: dict[AnnotPath, TypeExpr]</s>\n",
      "===========ref: spot.type_inference/TypeInfState.num_errors===========\n",
      "<s> <add> # spot.type_inference/TypeInfState.num_errors\n",
      " <add> num_errors: int</s>\n",
      "===========ref: spot.type_inference/TypeInfState.__str__===========\n",
      "<s> <add> # spot.type_inference/TypeInfState.__str__\n",
      " <add> def __str__(self):\n",
      " <add>     return f\"\"\"\n",
      " <add> num_errors: {self.num_errors}\n",
      " <add> num_to_annot: {len(self.to_annot)}\n",
      " <add> to_annotate: {self.to_annot}\n",
      " <add> ------------------------ code -------------------------------\n",
      " <add> {self.module.code}\n",
      " <add>         \"\"\"</s>\n",
      "===========ref: spot.type_inference/TypeInfAction.path===========\n",
      "<s> <add> # spot.type_inference/TypeInfAction.path\n",
      " <add> path: AnnotPath</s>\n",
      "===========ref: spot.type_inference/TypeInfAction.type===========\n",
      "<s> <add> # spot.type_inference/TypeInfAction.type\n",
      " <add> type: TypeExpr</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.__init__===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.__init__\n",
      " <add> def __init__(self, checker: MypyChecker, src_file: str):\n",
      " <add>     self.checker = checker\n",
      " <add>     self.src_file = realpath(src_file)\n",
      " <add>     self.original_src = read_file(src_file)\n",
      " <add>     self.state = TypeInfState(cst.Module([]), [], {}, 0)\n",
      " <add>     self.reset()</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.checker===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.checker\n",
      " <add> checker:...</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.src_file===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.src_file\n",
      " <add> src_file:...</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.original_src===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.original_src\n",
      " <add> original_src:...</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.state===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.state\n",
      " <add> state:...</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.reset===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.reset\n",
      " <add> def reset(self) -> None:\n",
      " <add>     write_file(self.src_file, self.original_src)\n",
      " <add>     self.state.module = cst.parse_module(self.original_src)\n",
      " <add>     paths, annots = collect_annotations(self.state.module)\n",
      " <add>     self.state.annotated = {k: v.annotation for k, v in annots.items()}\n",
      " <add>     self.state.to_annot = [p for p in paths if p not in annots]\n",
      " <add>     self.state.num_errors = self.checker.recheck_files(self.src_file).num_errors</s>\n",
      "===========ref: spot.type_inference/TypeInfEnv.step===========\n",
      "<s> <add> # spot.type_inference/TypeInfEnv.step\n",
      " <add> def step(self, action: TypeInfAction, check_any=False) -> None:\n",
      " <add>     assert action.path in self.state.to_annot, f\"Invalid action: path {action.path} already annotated.\"\n",
      " <add>     mod = apply_annotations(self.state.module, {action.path: cst.Annotation(action.type)})\n",
      " <add>     write_file(self.src_file, mod.code)\n",
      " <add>     ne = self.checker.recheck_files(self.src_file).num_errors\n",
      " <add>     if ne > self.state.num_errors:\n",
      " <add>         mod = apply_annotations(self.state.module, {action.path: cst.Annotation(cst.Name(\"Any\"))})\n",
      " <add>         write_file(self.src_file, mod.code)\n",
      " <add>         if check_any:\n",
      " <add>             check_r = self.checker.recheck_files(self.src_file)\n",
      " <add>             assert check_r.num_errors == self.state.num_errors, f\"Adding Any should not trigger more type errors.\\n\\\n",
      " <add> action: {action}\\n\\\n",
      " <add> mypy output: {check_r.output_str}\\n---------code---------\\n {mod.code}\"\n",
      " <add>     self.state.to_annot.remove(action.path)\n",
      " <add>     self.state.module = mod\n",
      " <add>     self.state.annotated[action.path] = action.type</s>\n",
      "===========ref: tests.test_type_checking/test_mypy_checker_1===========\n",
      "<s># tests.test_type_checking/test_mypy_checker_1\n",
      "def test_mypy_checker_1():\n",
      " <add>     with mypy_checker(\".venv/bin/dmypy\", \"data/code\") as checker:\n",
      " <add>         check_r = checker.check_code_dir()\n",
      " <add>         assert \"bad_code_1.py\" in check_r.num_error_dict\n",
      " <add>         assert \"bad_code_2.py\" in check_r.num_error_dict\n",
      " <del>     checker = MypyChecker(\".venv/bin/dmypy\", \"data/code\")\n",
      " <del>     check_r = checker.check_file(\".\")\n",
      " <del>     assert \"bad_code_1.py\" in check_r.num_error_dict\n",
      " <del>     assert \"bad_code_2.py\" in check_r.num_error_dict</s>\n",
      "===========ref: tests.test_type_checking/test_annotation_collection===========\n",
      "<s># tests.test_type_checking/test_annotation_collection\n",
      "def test_annotation_collection():\n",
      " <add>     annot_paths, _ = collect_annotations(parsed)\n",
      " <del>     annots = collect_annotations(parsed)\n",
      "    annot_places: list[AnnotPath] = [\n",
      "        annot_path(\"fib\", \"n\"),\n",
      "        annot_path(\"fib\", SpecialNames.Return),\n",
      "        annot_path(\"t_add\", \"x\"),\n",
      "        annot_path(\"t_add\", \"y\"),\n",
      "        annot_path(\"t_add\", SpecialNames.Return),\n",
      "        annot_path(\"x\"),\n",
      "    ]\n",
      "    for p in annot_places:\n",
      " <add>         assert p in annot_paths\n",
      " <del>         assert p in annots</s>\n",
      "===========ref: tests.test_type_checking/test_annotation_applying===========\n",
      "<s># tests.test_type_checking/test_annotation_applying\n",
      "def test_annotation_applying():\n",
      " <add>     _, old_annots = collect_annotations(parsed)\n",
      " <del>     old_annots = collect_annotations(parsed)\n",
      "    new_parsed = apply_annotations(parsed, code_1_patch)\n",
      " <add>     _, new_annots = collect_annotations(new_parsed)\n",
      " <del>     new_annots = collect_annotations(new_parsed)\n",
      "\n",
      "    for k, v in code_1_patch.items():\n",
      " <add>         assert old_annots[k].annotation!= new_annots[k].annotation\n",
      " <add>         assert new_annots[k].annotation == v.annotation\n",
      " <del>         assert not old_annots[k].annotation.deep_equals(new_annots[k].annotation)\n",
      " <del>         assert new_annots[k].annotation == (v.annotation)</s>\n",
      "===========ref: tests.test_type_checking/test_mypy_checker_2===========\n",
      "<s># tests.test_type_checking/test_mypy_checker_2\n",
      "def test_mypy_checker_2():\n",
      " <add>     with mypy_checker(\".venv/bin/dmypy\", \"data/code_output\") as checker:\n",
      " <add>         write_file(\"data/code_output/bad_code_1.py\", parsed.code)\n",
      " <add>         assert checker.recheck_files(\"bad_code_1.py\").num_errors > 0\n",
      " <add>         write_file(\n",
      " <add>             \"data/code_output/bad_code_1.py\",\n",
      " <add>             apply_annotations(parsed, code_1_patch).code,\n",
      " <add>         )\n",
      " <add>         assert checker.recheck_files(\"bad_code_1.py\").num_errors == 0\n",
      " <del>     out_checker = MypyChecker(\".venv/bin/dmypy\", \"data/code_output\")\n",
      " <del>     write_file(\"data/code_output/bad_code_1.py\", parsed.code)\n",
      " <del>     assert out_checker.check_file(\".\").num_errors > 0\n",
      " <del>     write_file(\"data/code_output/bad_code_1.py\", apply_annotations(parsed, code_1_patch).code)\n",
      " <del>     assert out_checker.check_file(\".\").num_errors == 0</s>\n"
     ]
    }
   ],
   "source": [
    "qedit = data.all_edits()[1]\n",
    "print(qedit.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edits with updated calls: 23 / 126\n",
      "Number of updated calls: 30\n"
     ]
    }
   ],
   "source": [
    "call_exs = [ex for ex in data.all_edits() if ex.updated_calls]\n",
    "print(f\"Edits with updated calls: {len(call_exs)} / {len(data.all_edits())}\")\n",
    "print(f\"Number of updated calls: {sum(len(ex.updated_calls) for ex in call_exs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=call_exs[1]\n",
    "print(f\"updated calls: {[p for p, _ in ex.updated_calls]}\")\n",
    "print(ex.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"SPOT\"\n",
    "dataset_name = \"medium\"\n",
    "# encoder = AnalysisBasedEditEncoder(extra_ctx_names=(\"usees\", \"post-usees\"))\n",
    "encoder = CstBasedEditEncoder()\n",
    "save_dir = get_dataset_dir(dataset_name) / repr_modified_args(encoder)\n",
    "datasets = load_datasets(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n",
      "n_projects: 20\n",
      "n_edits: 12666\n",
      "input_size:\n",
      "   mean: 2759.8\n",
      "   median: 3137.5\n",
      "   min: 44\n",
      "   max: 4006\n",
      "output_size:\n",
      "   mean: 113.73\n",
      "   median: 75\n",
      "   min: 3\n",
      "   max: 4776\n",
      "==================== valid ====================\n",
      "n_projects: 10\n",
      "n_edits: 2297\n",
      "input_size:\n",
      "   mean: 2902.8\n",
      "   median: 3629\n",
      "   min: 58\n",
      "   max: 4006\n",
      "output_size:\n",
      "   mean: 116.93\n",
      "   median: 89\n",
      "   min: 5\n",
      "   max: 1567\n",
      "==================== train ====================\n",
      "n_projects: 100\n",
      "n_edits: 50801\n",
      "input_size:\n",
      "   mean: 2579.5\n",
      "   median: 2720\n",
      "   min: 37\n",
      "   max: 4006\n",
      "output_size:\n",
      "   mean: 98.522\n",
      "   median: 64\n",
      "   min: 3\n",
      "   max: 8434\n"
     ]
    }
   ],
   "source": [
    "for group, dataset in datasets.items():\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    pretty_print_dict(dataset.overall_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All edits: 1331\n",
      "All edits with extra context: 360\n"
     ]
    }
   ],
   "source": [
    "with_ctx = [e for e in data.all_edits() if e.extra_tks]\n",
    "\n",
    "print(\"All edits:\", len(data.all_edits()))\n",
    "print(\"All edits with extra context:\", len(with_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coeditor.model import DatasetDecodingResult\n",
    "\n",
    "model_name = \"coeditor-medium-analysis-post_usees\"\n",
    "dec_result: DatasetDecodingResult = pickle_load(get_model_dir() / model_name / \"dec_result.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving examples: 100%|██████████| 200/200 [00:03<00:00, 57.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output examples saved to: /mnt/nas/jiayi/coeditor/models/models/trained/coeditor-medium-analysis-post_usees/pred_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_saved_samples = 200\n",
    "random.seed(42)\n",
    "exs_to_save = list(range(len(dec_result.predictions)))\n",
    "random.shuffle(exs_to_save)\n",
    "exs_to_save = exs_to_save[:max_saved_samples]\n",
    "out_dir = get_model_dir() / model_name / \"pred_samples\"\n",
    "dec_result.save_examples_to_dir(out_dir, exs_to_save)\n",
    "print(\"Output examples saved to:\", out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
