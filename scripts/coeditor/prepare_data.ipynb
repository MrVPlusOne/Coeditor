{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from coeditor.common import *\n",
    "from coeditor.dataset import *\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"medium\"\n",
    "# dataset_name = \"SPOT\"\n",
    "save_dir = get_dataset_dir(dataset_name) / \"tokenized-file_based\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting commit histories:   0%|          | 0/130 [00:00<?, ?repo/s]warning: inexact rename detection was skipped due to too many files.\n",
      "warning: you may want to set your diff.renameLimit variable to at least 2368 and retry the command.\n",
      "Getting commit histories: 100%|██████████| 130/130 [02:00<00:00,  1.08repo/s]\n",
      "Create tokenized edits:   2%|▏         | 7/397 [01:47<1:57:24, 18.06s/chunk]warning: inexact rename detection was skipped due to too many files.\n",
      "warning: you may want to set your diff.renameLimit variable to at least 2368 and retry the command.\n",
      "Create tokenized edits: 100%|██████████| 397/397 [17:43<00:00,  2.68s/chunk] \n"
     ]
    }
   ],
   "source": [
    "window = WindowArgs(4096)\n",
    "\n",
    "if dataset_name == \"SPOT\":\n",
    "    datasets = {\"test\": dataset_from_projects([proj_root()], window)}\n",
    "else:\n",
    "    datasets = datasets_from_repos(get_dataset_dir(dataset_name) / \"repos\", window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': TokenizedEditDataset(n_projects=20, n_edits=11804),\n",
       " 'valid': TokenizedEditDataset(n_projects=10, n_edits=2255),\n",
       " 'train': TokenizedEditDataset(n_projects=100, n_edits=46486)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset saved to: /mnt/nas/jiayi/coeditor/datasets/medium/tokenized-file_based\n"
     ]
    }
   ],
   "source": [
    "display(datasets)\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    pickle_dump(save_dir / f\"{name}.pkl\", dataset)\n",
    "\n",
    "print(\"Tokenized dataset saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>n_edits</th>\n",
       "      <th>avg_input_size</th>\n",
       "      <th>avg_target_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danielgatis?rembg</td>\n",
       "      <td>147</td>\n",
       "      <td>1657.993197</td>\n",
       "      <td>119.850340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>victoresque?pytorch-template</td>\n",
       "      <td>272</td>\n",
       "      <td>977.261029</td>\n",
       "      <td>79.360294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k4yt3x?video2x</td>\n",
       "      <td>919</td>\n",
       "      <td>2451.346028</td>\n",
       "      <td>140.348205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wzpan?wukong-robot</td>\n",
       "      <td>574</td>\n",
       "      <td>1788.189895</td>\n",
       "      <td>67.885017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morizeyao?GPT2-Chinese</td>\n",
       "      <td>16</td>\n",
       "      <td>3024.687500</td>\n",
       "      <td>126.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>awslabs?autogluon</td>\n",
       "      <td>5356</td>\n",
       "      <td>2765.761949</td>\n",
       "      <td>125.125093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deezer?spleeter</td>\n",
       "      <td>290</td>\n",
       "      <td>1747.086207</td>\n",
       "      <td>80.165517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ultralytics?yolov5</td>\n",
       "      <td>1111</td>\n",
       "      <td>3047.018902</td>\n",
       "      <td>111.352835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>seemoo-lab?opendrop</td>\n",
       "      <td>153</td>\n",
       "      <td>3238.071895</td>\n",
       "      <td>97.124183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deepmind?alphafold</td>\n",
       "      <td>137</td>\n",
       "      <td>2763.459854</td>\n",
       "      <td>165.255474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sanster?lama-cleaner</td>\n",
       "      <td>206</td>\n",
       "      <td>1876.864078</td>\n",
       "      <td>97.616505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>STVIR?pysot</td>\n",
       "      <td>35</td>\n",
       "      <td>1307.542857</td>\n",
       "      <td>78.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shawn-Shan?fawkes</td>\n",
       "      <td>188</td>\n",
       "      <td>2913.015957</td>\n",
       "      <td>143.728723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EZFNDEV?EZFN-Lobbybot</td>\n",
       "      <td>72</td>\n",
       "      <td>1953.972222</td>\n",
       "      <td>99.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stewartmcgown?uds</td>\n",
       "      <td>189</td>\n",
       "      <td>2764.714286</td>\n",
       "      <td>85.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>archlinux?archinstall</td>\n",
       "      <td>849</td>\n",
       "      <td>3059.215548</td>\n",
       "      <td>90.163722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sfyc23?EverydayWechat</td>\n",
       "      <td>254</td>\n",
       "      <td>1960.763780</td>\n",
       "      <td>115.637795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bojone?bert4keras</td>\n",
       "      <td>541</td>\n",
       "      <td>2918.670980</td>\n",
       "      <td>102.048059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pjialin?py12306</td>\n",
       "      <td>418</td>\n",
       "      <td>2284.071770</td>\n",
       "      <td>70.734450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>google-research?bert</td>\n",
       "      <td>77</td>\n",
       "      <td>3505.883117</td>\n",
       "      <td>138.753247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            repo  n_edits  avg_input_size  avg_target_size\n",
       "0              danielgatis?rembg      147     1657.993197       119.850340\n",
       "1   victoresque?pytorch-template      272      977.261029        79.360294\n",
       "2                 k4yt3x?video2x      919     2451.346028       140.348205\n",
       "3             wzpan?wukong-robot      574     1788.189895        67.885017\n",
       "4         Morizeyao?GPT2-Chinese       16     3024.687500       126.437500\n",
       "5              awslabs?autogluon     5356     2765.761949       125.125093\n",
       "6                deezer?spleeter      290     1747.086207        80.165517\n",
       "7             ultralytics?yolov5     1111     3047.018902       111.352835\n",
       "8            seemoo-lab?opendrop      153     3238.071895        97.124183\n",
       "9             deepmind?alphafold      137     2763.459854       165.255474\n",
       "10          Sanster?lama-cleaner      206     1876.864078        97.616505\n",
       "11                   STVIR?pysot       35     1307.542857        78.428571\n",
       "12             Shawn-Shan?fawkes      188     2913.015957       143.728723\n",
       "13         EZFNDEV?EZFN-Lobbybot       72     1953.972222        99.083333\n",
       "14             stewartmcgown?uds      189     2764.714286        85.634921\n",
       "15         archlinux?archinstall      849     3059.215548        90.163722\n",
       "16         sfyc23?EverydayWechat      254     1960.763780       115.637795\n",
       "17             bojone?bert4keras      541     2918.670980       102.048059\n",
       "18               pjialin?py12306      418     2284.071770        70.734450\n",
       "19          google-research?bert       77     3505.883117       138.753247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== valid ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>n_edits</th>\n",
       "      <th>avg_input_size</th>\n",
       "      <th>avg_target_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ownthink?KnowledgeGraphData</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai?gpt-2</td>\n",
       "      <td>16</td>\n",
       "      <td>751.750000</td>\n",
       "      <td>102.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bloomberg?memray</td>\n",
       "      <td>1054</td>\n",
       "      <td>2672.277989</td>\n",
       "      <td>105.074953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParthJadhav?Tkinter-Designer</td>\n",
       "      <td>88</td>\n",
       "      <td>1650.659091</td>\n",
       "      <td>98.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hunshcn?gh-proxy</td>\n",
       "      <td>24</td>\n",
       "      <td>1527.416667</td>\n",
       "      <td>126.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>schenkd?nginx-ui</td>\n",
       "      <td>10</td>\n",
       "      <td>1399.100000</td>\n",
       "      <td>53.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ultralytics?yolov3</td>\n",
       "      <td>966</td>\n",
       "      <td>3056.662526</td>\n",
       "      <td>131.274327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nuno-faria?tiler</td>\n",
       "      <td>10</td>\n",
       "      <td>1975.500000</td>\n",
       "      <td>45.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TencentARC?GFPGAN</td>\n",
       "      <td>51</td>\n",
       "      <td>2319.490196</td>\n",
       "      <td>192.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cloudflare?flan</td>\n",
       "      <td>36</td>\n",
       "      <td>1623.805556</td>\n",
       "      <td>114.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           repo  n_edits  avg_input_size  avg_target_size\n",
       "0   ownthink?KnowledgeGraphData        0             NaN              NaN\n",
       "1                  openai?gpt-2       16      751.750000       102.187500\n",
       "2              bloomberg?memray     1054     2672.277989       105.074953\n",
       "3  ParthJadhav?Tkinter-Designer       88     1650.659091        98.397727\n",
       "4              hunshcn?gh-proxy       24     1527.416667       126.708333\n",
       "5              schenkd?nginx-ui       10     1399.100000        53.600000\n",
       "6            ultralytics?yolov3      966     3056.662526       131.274327\n",
       "7              nuno-faria?tiler       10     1975.500000        45.600000\n",
       "8             TencentARC?GFPGAN       51     2319.490196       192.117647\n",
       "9               cloudflare?flan       36     1623.805556       114.722222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== train ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>n_edits</th>\n",
       "      <th>avg_input_size</th>\n",
       "      <th>avg_target_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVlabs?stylegan2</td>\n",
       "      <td>13</td>\n",
       "      <td>2033.692308</td>\n",
       "      <td>98.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaggle?kaggle-api</td>\n",
       "      <td>306</td>\n",
       "      <td>3610.382353</td>\n",
       "      <td>140.575163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sebastianruder?NLP-progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebookresearch?detr</td>\n",
       "      <td>59</td>\n",
       "      <td>2551.711864</td>\n",
       "      <td>94.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rafaelpadilla?Object-Detection-Metrics</td>\n",
       "      <td>45</td>\n",
       "      <td>2098.711111</td>\n",
       "      <td>152.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>yoshiko2?Movie_Data_Capture</td>\n",
       "      <td>975</td>\n",
       "      <td>2876.294359</td>\n",
       "      <td>133.909744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PeterL1n?RobustVideoMatting</td>\n",
       "      <td>7</td>\n",
       "      <td>2185.142857</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>jackzhenguo?python-small-examples</td>\n",
       "      <td>2</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>karpathy?minGPT</td>\n",
       "      <td>88</td>\n",
       "      <td>1869.215909</td>\n",
       "      <td>85.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Netflix?metaflow</td>\n",
       "      <td>1485</td>\n",
       "      <td>2796.489562</td>\n",
       "      <td>104.207407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      repo  n_edits  avg_input_size  \\\n",
       "0                         NVlabs?stylegan2       13     2033.692308   \n",
       "1                        Kaggle?kaggle-api      306     3610.382353   \n",
       "2              sebastianruder?NLP-progress        0             NaN   \n",
       "3                    facebookresearch?detr       59     2551.711864   \n",
       "4   rafaelpadilla?Object-Detection-Metrics       45     2098.711111   \n",
       "..                                     ...      ...             ...   \n",
       "95             yoshiko2?Movie_Data_Capture      975     2876.294359   \n",
       "96             PeterL1n?RobustVideoMatting        7     2185.142857   \n",
       "97       jackzhenguo?python-small-examples        2      170.000000   \n",
       "98                         karpathy?minGPT       88     1869.215909   \n",
       "99                        Netflix?metaflow     1485     2796.489562   \n",
       "\n",
       "    avg_target_size  \n",
       "0         98.307692  \n",
       "1        140.575163  \n",
       "2               NaN  \n",
       "3         94.847458  \n",
       "4        152.822222  \n",
       "..              ...  \n",
       "95       133.909744  \n",
       "96        72.000000  \n",
       "97       110.000000  \n",
       "98        85.613636  \n",
       "99       104.207407  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for group in datasets:\n",
    "    if not (save_dir / f\"{group}.pkl\").exists():\n",
    "        continue\n",
    "    dataset = pickle_load(save_dir / f\"{group}.pkl\")\n",
    "    print(\"=\" * 20, group, \"=\" * 20)\n",
    "    display(dataset.per_repo_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Left Context========\n",
      "np.int)\n",
      "\n",
      "    is_foreground = binary_erosion(is_foreground, structure=structure)\n",
      "    is_background = binary_erosion(is_background, structure=structure, border_value=1)\n",
      "\n",
      "    trimap = np.full(mask.shape, dtype=np.uint8, fill_value=128)\n",
      "    trimap[is_foreground] = 255\n",
      "    trimap[is_background] = 0\n",
      "\n",
      "    img_normalized = img / 255.0\n",
      "    trimap_normalized = trimap / 255.0\n",
      "\n",
      "    alpha = estimate_alpha_cf(img_normalized, trimap_normalized)\n",
      "    foreground = estimate_foreground_ml(img_normalized, alpha)\n",
      "    cutout = stack_images(foreground, alpha)\n",
      "\n",
      "    cutout = np.clip(cutout * 255, 0, 255).astype(np.uint8)\n",
      "    cutout = Image.fromarray(cutout)\n",
      "    cutout = cutout.resize(size, Image.LANCZOS)\n",
      "\n",
      "    return cutout\n",
      "\n",
      "\n",
      "def naive_cutout(img, mask):\n",
      "    empty = Image.new(\"RGBA\", (img.size), 0)\n",
      "    cutout = Image.composite(img, empty, mask.resize(img.size, Image.LANCZOS))\n",
      "    return cutout\n",
      "\n",
      "\n",
      " <del> def get_model(model_name):\n",
      " <del>     if model_name == \"u2netp\":\n",
      " <del>         return load_model(model_name=\"u2netp\")\n",
      " <del>     if model_name == \"u2net_human_seg\":\n",
      " <del>         return load_model(model_name=\"u2net_human_seg\")\n",
      " <del>     else:\n",
      " <del>         return load_model(model_name=\"u2net\")\n",
      " <del> \n",
      " <del> \n",
      "def resize_image(img, width, height):\n",
      "    original_width, original_height = img.size\n",
      "    width = original_width if width is None else width\n",
      "    height = original_height if height is None else height\n",
      "    return (\n",
      "        img.resize((width, height))\n",
      "        if original_width!= width or original_height!= height\n",
      "        else img\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "========Ground Truth========\n",
      "<extra_id_2>: <add>     session=None,\n",
      " <del>\n",
      "<extra_id_15>: <add>     if session is None:\n",
      " <add>         session = ort_session(model_name)\n",
      " <add> \n",
      " <add>     mask = predict(session, np.array(img)).convert(\"L\")\n",
      " <del>\n",
      "<extra_id_16>: <del>\n",
      "========Main Code========\n",
      "<extra_id_0>def remove(\n",
      "<extra_id_1>    data,\n",
      "<extra_id_2>    model_name=\"u2net\",\n",
      "<extra_id_3>    alpha_matting=False,\n",
      "<extra_id_4>    alpha_matting_foreground_threshold=240,\n",
      "<extra_id_5>    alpha_matting_background_threshold=10,\n",
      "<extra_id_6>    alpha_matting_erode_structure_size=10,\n",
      "<extra_id_7>    alpha_matting_base_size=1000,\n",
      "<extra_id_8>    width=None,\n",
      "<extra_id_9>    height=None,\n",
      "<extra_id_10>):\n",
      "<extra_id_11>    img = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
      "<extra_id_12>    if width is not None or height is not None:\n",
      "<extra_id_13>        img = resize_image(img, width, height)\n",
      "<extra_id_14>\n",
      "<extra_id_15>    model = get_model(model_name)\n",
      "<extra_id_16>    mask = predict(model, np.array(img)).convert(\"L\")\n",
      "<extra_id_17>\n",
      "<extra_id_18>    if alpha_matting:\n",
      "<extra_id_19>        try:\n",
      "<extra_id_20>            cutout = alpha_matting_cutout(\n",
      "<extra_id_21>                img,\n",
      "<extra_id_22>                mask,\n",
      "<extra_id_23>                alpha_matting_foreground_threshold,\n",
      "<extra_id_24>                alpha_matting_background_threshold,\n",
      "<extra_id_25>                alpha_matting_erode_structure_size,\n",
      "<extra_id_26>                alpha_matting_base_size,\n",
      "<extra_id_27>            )\n",
      "<extra_id_28>        except Exception:\n",
      "<extra_id_29>            cutout = naive_cutout(img, mask)\n",
      "<extra_id_30>    else:\n",
      "<extra_id_31>        cutout = naive_cutout(img, mask)\n",
      "<extra_id_32>\n",
      "<extra_id_33>    bio = io.BytesIO()\n",
      "<extra_id_34>    cutout.save(bio, \"PNG\")\n",
      "<extra_id_35>\n",
      "<extra_id_36>    return bio.getbuffer()\n",
      "<extra_id_37>\n",
      "========Right Context========\n",
      "\n",
      "    return bio.getbuffer()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list(datasets[\"test\"].all_edits())[0].show_prediction())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
