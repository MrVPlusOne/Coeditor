{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import libcst as cst\n",
    "from tqdm import tqdm\n",
    "\n",
    "from spot.data import GitRepo\n",
    "from spot.type_env import collect_annots_info, mypy_checker\n",
    "from spot.utils import proj_root, read_file, write_file\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 63476337,\n",
       " 'node_id': 'MDEwOlJlcG9zaXRvcnk2MzQ3NjMzNw==',\n",
       " 'name': 'Python',\n",
       " 'full_name': 'TheAlgorithms/Python',\n",
       " 'private': False,\n",
       " 'owner': {'login': 'TheAlgorithms',\n",
       "  'id': 20487725,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjIwNDg3NzI1',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/20487725?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/TheAlgorithms',\n",
       "  'html_url': 'https://github.com/TheAlgorithms',\n",
       "  'followers_url': 'https://api.github.com/users/TheAlgorithms/followers',\n",
       "  'following_url': 'https://api.github.com/users/TheAlgorithms/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/TheAlgorithms/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/TheAlgorithms/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/TheAlgorithms/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/TheAlgorithms/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/TheAlgorithms/repos',\n",
       "  'events_url': 'https://api.github.com/users/TheAlgorithms/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/TheAlgorithms/received_events',\n",
       "  'type': 'Organization',\n",
       "  'site_admin': False},\n",
       " 'html_url': 'https://github.com/TheAlgorithms/Python',\n",
       " 'description': 'All Algorithms implemented in Python',\n",
       " 'fork': False,\n",
       " 'url': 'https://api.github.com/repos/TheAlgorithms/Python',\n",
       " 'forks_url': 'https://api.github.com/repos/TheAlgorithms/Python/forks',\n",
       " 'keys_url': 'https://api.github.com/repos/TheAlgorithms/Python/keys{/key_id}',\n",
       " 'collaborators_url': 'https://api.github.com/repos/TheAlgorithms/Python/collaborators{/collaborator}',\n",
       " 'teams_url': 'https://api.github.com/repos/TheAlgorithms/Python/teams',\n",
       " 'hooks_url': 'https://api.github.com/repos/TheAlgorithms/Python/hooks',\n",
       " 'issue_events_url': 'https://api.github.com/repos/TheAlgorithms/Python/issues/events{/number}',\n",
       " 'events_url': 'https://api.github.com/repos/TheAlgorithms/Python/events',\n",
       " 'assignees_url': 'https://api.github.com/repos/TheAlgorithms/Python/assignees{/user}',\n",
       " 'branches_url': 'https://api.github.com/repos/TheAlgorithms/Python/branches{/branch}',\n",
       " 'tags_url': 'https://api.github.com/repos/TheAlgorithms/Python/tags',\n",
       " 'blobs_url': 'https://api.github.com/repos/TheAlgorithms/Python/git/blobs{/sha}',\n",
       " 'git_tags_url': 'https://api.github.com/repos/TheAlgorithms/Python/git/tags{/sha}',\n",
       " 'git_refs_url': 'https://api.github.com/repos/TheAlgorithms/Python/git/refs{/sha}',\n",
       " 'trees_url': 'https://api.github.com/repos/TheAlgorithms/Python/git/trees{/sha}',\n",
       " 'statuses_url': 'https://api.github.com/repos/TheAlgorithms/Python/statuses/{sha}',\n",
       " 'languages_url': 'https://api.github.com/repos/TheAlgorithms/Python/languages',\n",
       " 'stargazers_url': 'https://api.github.com/repos/TheAlgorithms/Python/stargazers',\n",
       " 'contributors_url': 'https://api.github.com/repos/TheAlgorithms/Python/contributors',\n",
       " 'subscribers_url': 'https://api.github.com/repos/TheAlgorithms/Python/subscribers',\n",
       " 'subscription_url': 'https://api.github.com/repos/TheAlgorithms/Python/subscription',\n",
       " 'commits_url': 'https://api.github.com/repos/TheAlgorithms/Python/commits{/sha}',\n",
       " 'git_commits_url': 'https://api.github.com/repos/TheAlgorithms/Python/git/commits{/sha}',\n",
       " 'comments_url': 'https://api.github.com/repos/TheAlgorithms/Python/comments{/number}',\n",
       " 'issue_comment_url': 'https://api.github.com/repos/TheAlgorithms/Python/issues/comments{/number}',\n",
       " 'contents_url': 'https://api.github.com/repos/TheAlgorithms/Python/contents/{+path}',\n",
       " 'compare_url': 'https://api.github.com/repos/TheAlgorithms/Python/compare/{base}...{head}',\n",
       " 'merges_url': 'https://api.github.com/repos/TheAlgorithms/Python/merges',\n",
       " 'archive_url': 'https://api.github.com/repos/TheAlgorithms/Python/{archive_format}{/ref}',\n",
       " 'downloads_url': 'https://api.github.com/repos/TheAlgorithms/Python/downloads',\n",
       " 'issues_url': 'https://api.github.com/repos/TheAlgorithms/Python/issues{/number}',\n",
       " 'pulls_url': 'https://api.github.com/repos/TheAlgorithms/Python/pulls{/number}',\n",
       " 'milestones_url': 'https://api.github.com/repos/TheAlgorithms/Python/milestones{/number}',\n",
       " 'notifications_url': 'https://api.github.com/repos/TheAlgorithms/Python/notifications{?since,all,participating}',\n",
       " 'labels_url': 'https://api.github.com/repos/TheAlgorithms/Python/labels{/name}',\n",
       " 'releases_url': 'https://api.github.com/repos/TheAlgorithms/Python/releases{/id}',\n",
       " 'deployments_url': 'https://api.github.com/repos/TheAlgorithms/Python/deployments',\n",
       " 'created_at': '2016-07-16T09:44:01Z',\n",
       " 'updated_at': '2022-06-05T18:29:07Z',\n",
       " 'pushed_at': '2022-06-04T19:27:47Z',\n",
       " 'git_url': 'git://github.com/TheAlgorithms/Python.git',\n",
       " 'ssh_url': 'git@github.com:TheAlgorithms/Python.git',\n",
       " 'clone_url': 'https://github.com/TheAlgorithms/Python.git',\n",
       " 'svn_url': 'https://github.com/TheAlgorithms/Python',\n",
       " 'homepage': 'https://the-algorithms.com/',\n",
       " 'size': 12537,\n",
       " 'stargazers_count': 136711,\n",
       " 'watchers_count': 136711,\n",
       " 'language': 'Python',\n",
       " 'has_issues': True,\n",
       " 'has_projects': True,\n",
       " 'has_downloads': True,\n",
       " 'has_wiki': True,\n",
       " 'has_pages': False,\n",
       " 'forks_count': 35664,\n",
       " 'mirror_url': None,\n",
       " 'archived': False,\n",
       " 'disabled': False,\n",
       " 'open_issues_count': 242,\n",
       " 'license': {'key': 'mit',\n",
       "  'name': 'MIT License',\n",
       "  'spdx_id': 'MIT',\n",
       "  'url': 'https://api.github.com/licenses/mit',\n",
       "  'node_id': 'MDc6TGljZW5zZTEz'},\n",
       " 'allow_forking': True,\n",
       " 'is_template': False,\n",
       " 'topics': ['algorithm',\n",
       "  'algorithm-competitions',\n",
       "  'algorithms-implemented',\n",
       "  'algos',\n",
       "  'community-driven',\n",
       "  'education',\n",
       "  'hacktoberfest',\n",
       "  'interview',\n",
       "  'learn',\n",
       "  'practice',\n",
       "  'python',\n",
       "  'searches',\n",
       "  'sorting-algorithms',\n",
       "  'sorts'],\n",
       " 'visibility': 'public',\n",
       " 'forks': 35664,\n",
       " 'open_issues': 242,\n",
       " 'watchers': 136711,\n",
       " 'default_branch': 'master',\n",
       " 'score': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\n",
    "    f\"https://api.github.com/search/repositories?q=language:python&sort=stars&order=desc&per_page=10\"\n",
    ").json()[\"items\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dateparser\n",
    "\n",
    "\n",
    "def fetch_top_python_repos(n_pages: int, oldest_push: str):\n",
    "    def request_page(page: int):\n",
    "        return requests.get(\n",
    "            f\"https://api.github.com/search/repositories?q=language:python&pushed_at>{oldest_push}&sort=stars&order=desc&per_page=100&page={page}\"\n",
    "        ).json()\n",
    "\n",
    "    pages = map(request_page, range(1, n_pages + 1))\n",
    "    repos = list[GitRepo]()\n",
    "    for page in tqdm(pages, desc=\"process pages\"):\n",
    "        if \"items\" not in page:\n",
    "            print(\"Fetching page failed:\")\n",
    "            print(page)\n",
    "            break\n",
    "        for item in page[\"items\"]:\n",
    "            r = GitRepo(\n",
    "                author=item[\"owner\"][\"login\"],\n",
    "                name=item[\"name\"],\n",
    "                url=item[\"html_url\"],\n",
    "                description=item[\"description\"],\n",
    "                stars=item[\"stargazers_count\"],\n",
    "                forks=item[\"forks_count\"],\n",
    "                last_update=dateparser.parse(item[\"pushed_at\"]).replace(tzinfo=None),\n",
    "            )\n",
    "            repos.append(r)\n",
    "    return repos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "process pages: 10it [00:26,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page failed:\n",
      "{'message': \"API rate limit exceeded for 128.83.122.136. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", 'documentation_url': 'https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_repos = fetch_top_python_repos(50, oldest_push=\"2021-04-20T00:00:01Z\")\n",
    "len(top_repos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GitRepo(author='donnemartin', name='system-design-primer', url='https://github.com/donnemartin/system-design-primer', stars=182777, forks=33244, lines_of_code=None, last_update=datetime.datetime(2022, 5, 28, 11, 54, 39), n_type_annots=None, n_type_places=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_repos[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = json.loads(read_file(\"data/mypy-dependents-by-stars.json\"))\n",
    "all_repos = [GitRepo.from_json(r) for r in all_repos]\n",
    "# all_repos=all_repos[:10] # for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repos already downloaded.\n",
      "Reading last updates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4890/4890 [00:27<00:00, 175.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 4890/5996 repos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download all candidate repos\n",
    "\n",
    "\n",
    "def clear_downloaded_repos(repos_dir):\n",
    "    shutil.rmtree(repos_dir)\n",
    "\n",
    "\n",
    "def download_repos(\n",
    "    to_download: list[GitRepo], repos_dir, download_timeout=10.0, max_workers=10\n",
    ") -> list[GitRepo]:\n",
    "    def download_single(repo: GitRepo):\n",
    "        try:\n",
    "            if repo.download(repos_dir, timeout=download_timeout):\n",
    "                repo.read_last_update(repos_dir)\n",
    "                return repo\n",
    "            else:\n",
    "                return None\n",
    "        except subprocess.TimeoutExpired:\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to download {repo.name}. Exception: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"Downloading repos from Github...\")\n",
    "    t_start = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        fs = [executor.submit(download_single, repo) for repo in to_download]\n",
    "        rs = [f.result() for f in tqdm(as_completed(fs), total=len(fs))]\n",
    "    print(f\"Downloading took {time.time() - t_start} seconds.\")\n",
    "    downloaded = [r for r in rs if r is not None]\n",
    "    return downloaded\n",
    "\n",
    "\n",
    "datadir = Path(os.getenv(\"datadir\"))\n",
    "repos_dir = datadir / \"SPOT-data/repos\"\n",
    "if not repos_dir.exists():\n",
    "    (repos_dir / \"downloading\").mkdir(parents=True)\n",
    "    (repos_dir / \"downloaded\").mkdir(parents=True)\n",
    "    downloaded_repos = download_repos(all_repos, repos_dir)\n",
    "    print(\"Deleting failed repos...\")\n",
    "    shutil.rmtree(repos_dir / \"downloading\")\n",
    "else:\n",
    "    print(\"Repos already downloaded.\")\n",
    "    downloaded_dirs = set(d.name for d in (repos_dir / \"downloaded\").iterdir())\n",
    "    downloaded_repos = [r for r in all_repos if r.authorname() in downloaded_dirs]\n",
    "    print(\"Reading last updates...\")\n",
    "    for r in tqdm(downloaded_repos):\n",
    "        r.read_last_update(repos_dir)\n",
    "print(f\"Downloaded {len(downloaded_repos)}/{len(all_repos)} repos.\")\n",
    "\n",
    "# assert len(list((repos_dir / \"downloaded\").iterdir())) == len(downloaded_repos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218 / 4890 repos are updated within a year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [00:05<00:00, 243.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181/1218 repos are within the size limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "date_threshold = datetime(2021, 4, 20)\n",
    "new_repos = [r for r in downloaded_repos if r.last_update > date_threshold]\n",
    "print(f\"{len(new_repos)} / {len(downloaded_repos)} repos are updated within a year.\")\n",
    "loc_limit = 50000\n",
    "\n",
    "small_repos = []\n",
    "for rep in tqdm(new_repos):\n",
    "    try:\n",
    "        loc = rep.count_lines_of_code(repos_dir)\n",
    "        if loc < loc_limit:\n",
    "            small_repos.append(rep)\n",
    "    except UnicodeDecodeError:\n",
    "        # nothing we can do\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to count lines of code for {rep.name}. Exception: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"{len(small_repos)}/{len(new_repos)} repos are within the size limit ({loc_limit} LOC).\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1181 [00:00<?, ?it/s]WARNING:root:Failed to count annotations for common-workflow-language. Exception: Syntax Error @ 24:23.\n",
      "Incomplete input. Encountered 'linenum', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "                print linenum, l.rstrip()\n",
      "                      ^\n",
      "  1%|          | 6/1181 [00:00<03:12,  6.10it/s]WARNING:root:Failed to count annotations for rchain. Exception: Syntax Error @ 22:15.\n",
      "Incomplete input. Encountered '\"Test Plan:\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"Test Plan:\", self.test_name\n",
      "              ^\n",
      "  1%|          | 14/1181 [00:02<03:14,  6.00it/s]WARNING:root:Failed to count annotations for Transcrypt. Exception: Syntax Error @ 1:1.\n",
      "Incomplete input. Unexpectedly encountered '='.\n",
      "\n",
      "= nonsense =\n",
      "^\n",
      "  2%|▏         | 26/1181 [00:03<01:55, 10.01it/s]WARNING:root:Failed to count annotations for canmatrix. Exception: Syntax Error @ 70:15.\n",
      "Incomplete input. Encountered '\"not yet working script for generating a communication layer for dedicated ECU out of can database\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"not yet working script for generating a communication layer for dedicated ECU out of can database\"\n",
      "              ^\n",
      "  3%|▎         | 35/1181 [00:04<02:18,  8.30it/s]WARNING:root:Failed to count annotations for cookiecutter-django-vue. Exception: Syntax Error @ 26:2.\n",
      "Incomplete input. Unexpectedly encountered '%'.\n",
      "\n",
      "{% if cookiecutter.use_sentry == 'y' -%}\n",
      " ^\n",
      "  5%|▌         | 63/1181 [00:09<03:55,  4.75it/s]WARNING:root:Failed to count annotations for kuyruk. Exception: Syntax Error @ 21:11.\n",
      "Incomplete input. Encountered '\"Done.\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "    print \"Done.\"\n",
      "          ^\n",
      "  7%|▋         | 80/1181 [00:11<02:34,  7.13it/s]WARNING:root:Failed to count annotations for create-aio-app. Exception: Syntax Error @ 2:2.\n",
      "Incomplete input. Unexpectedly encountered '%'.\n",
      "\n",
      "{%- if cookiecutter.use_postgres == 'y' %}\n",
      " ^\n",
      "  9%|▉         | 106/1181 [00:13<01:36, 11.18it/s]WARNING:root:Failed to count annotations for conversationai-models. Exception: Syntax Error @ 80:9.\n",
      "Incomplete input. Unexpectedly encountered an indent.\n",
      "\n",
      "        writer.summary.add_str, i)\n",
      "        ^\n",
      "  9%|▉         | 112/1181 [00:14<01:35, 11.15it/s]WARNING:root:Failed to count annotations for datawig. Exception: Syntax Error @ 237:5.\n",
      "Incomplete input. Encountered 'df', but expected ')'.\n",
      "\n",
      "    df['mse_percent'] = df.mse / df.groupby(['data','missingness','percent_missing'])['mse'].transform(max)\n",
      "    ^\n",
      " 10%|▉         | 118/1181 [00:14<01:40, 10.62it/s]WARNING:root:Failed to count annotations for Clean-code-in-Python. Exception: Syntax Error @ 13:2.\n",
      "Incomplete input. Encountered '(', but expected 'NAME'.\n",
      "\n",
      "@(lambda f: lambda *args, **kwargs: _log(f, *args, **kwargs))\n",
      " ^\n",
      "WARNING:root:Failed to count annotations for wemake-python-styleguide. Exception: Syntax Error @ 8:16.\n",
      "Incomplete input. Encountered '[', but expected '(', or 'NEWLINE'.\n",
      "\n",
      "@some_decorator['text']  # noqa: WPS466\n",
      "               ^\n",
      " 11%|█         | 126/1181 [00:15<00:51, 20.45it/s]WARNING:root:Failed to count annotations for network-programmability-stream. Exception: Syntax Error @ 21:58.\n",
      "Incomplete input. Unexpectedly encountered ':'.\n",
      "\n",
      "    with arista_driver(**ARISTA_SW_PARAMS) as arista_sw, :\n",
      "                                                         ^\n",
      " 11%|█         | 129/1181 [00:15<01:30, 11.62it/s]WARNING:root:Failed to count annotations for tomodachi. Exception: Syntax Error @ 2:26.\n",
      "Incomplete input. Encountered '\\n', but expected 'NAME'.\n",
      "\n",
      "import tomodachi.  # noqa\n",
      "                         ^\n",
      " 11%|█▏        | 135/1181 [00:16<01:32, 11.26it/s]WARNING:root:Failed to count annotations for python-best-practices-cookiecutter. Exception: Syntax Error @ 3:6.\n",
      "Incomplete input. Encountered '{', but expected '.', '...', or 'NAME'.\n",
      "\n",
      "from {{cookiecutter.repo_name}}.{{cookiecutter.repo_name}} import fib\n",
      "     ^\n",
      "WARNING:root:Failed to count annotations for guillotina. Exception: Syntax Error @ 7:24.\n",
      "Incomplete input. Encountered '{', but expected ')', '*', '**', or 'NAME'.\n",
      "\n",
      "async def test_install({{cookiecutter.package_name}}_requester):  # noqa\n",
      "                       ^\n",
      " 12%|█▏        | 141/1181 [00:16<01:35, 10.88it/s]WARNING:root:Failed to count annotations for treasure-boxes. Exception: Syntax Error @ 67:227.\n",
      "Incomplete input. Encountered '\\n', but expected 'NAME'.\n",
      "\n",
      "                lst_last_transaction_collection_id.append(each_purpose['LastTransactionCollectionPointId']) . #this identifies the last collecpoint where consent was given (Example : web form , newsletter subsciption page etc)\n",
      "                                                                                                                                                                                                                                  ^\n",
      " 13%|█▎        | 149/1181 [00:17<01:19, 12.96it/s]WARNING:root:Failed to count annotations for entity-controller. Exception: Syntax Error @ 66:5.\n",
      "Incomplete input. Encountered '\"\"\"Test is_on, turn_on, turn_off methods.\"\"\"', but expected 'INDENT'.\n",
      "\n",
      "    \"\"\"Test is_on, turn_on, turn_off methods.\"\"\"\n",
      "    ^\n",
      " 15%|█▍        | 172/1181 [00:19<01:17, 13.01it/s]WARNING:root:Failed to count annotations for shopify_python. Exception: Syntax Error @ 5:18.\n",
      "Incomplete input. Encountered ',', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "raise MyException, 'message'  # [two-arg-exception]\n",
      "                 ^\n",
      " 16%|█▋        | 193/1181 [00:21<01:28, 11.14it/s]WARNING:root:Failed to count annotations for slapos. Exception: Syntax Error @ 218:26.\n",
      "Incomplete input. Encountered '600', but expected ')'.\n",
      "\n",
      "        os.mkfifo(fifo, 0600)\n",
      "                         ^\n",
      " 20%|██        | 237/1181 [00:25<01:27, 10.82it/s]WARNING:root:Failed to count annotations for pyborg-1up. Exception: Syntax Error @ 43:15.\n",
      "Incomplete input. Encountered '\"Connection from \"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"Connection from \", self.request.getpeername()\n",
      "              ^\n",
      " 21%|██        | 243/1181 [00:26<02:32,  6.16it/s]WARNING:root:Failed to count annotations for arxiv-browse. Exception: Syntax Error @ 219:63.\n",
      "Internal error: There must be at least one space before 'as'.\n",
      "\n",
      "        with open(LOG_FILE_NAME, 'w', buffering=1)as report_fh:\n",
      "                                                              ^\n",
      " 21%|██        | 246/1181 [00:26<01:48,  8.60it/s]WARNING:root:Failed to count annotations for pandachaika. Exception: Syntax Error @ 1:10.\n",
      "Internal error: Must have at least one space after import.\n",
      "\n",
      "﻿import io\n",
      "         ^\n",
      "WARNING:root:Failed to count annotations for toolkit. Exception: division by zero\n",
      " 22%|██▏       | 257/1181 [00:26<00:47, 19.40it/s]WARNING:root:Failed to count annotations for tractor. Exception: Syntax Error @ 76:37.\n",
      "Incomplete input. Encountered 'as', but expected ')'.\n",
      "\n",
      "                trio.open_nursery() as n,\n",
      "                                    ^\n",
      " 22%|██▏       | 260/1181 [00:27<00:51, 17.72it/s]WARNING:root:Failed to count annotations for ethdkg. Exception: Syntax Error @ 3:10.\n",
      "Incomplete input. Encountered '\"python3.7 -m ethdkg\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "pkill -f \"python3.7 -m ethdkg\"\n",
      "         ^\n",
      " 22%|██▏       | 263/1181 [00:27<00:58, 15.71it/s]WARNING:root:Failed to count annotations for lightbus. Exception: Syntax Error @ 126:1.\n",
      "Incomplete input. Unexpectedly encountered '>>'.\n",
      "\n",
      ">>> bus.get_api_schema()\n",
      "^\n",
      " 23%|██▎       | 271/1181 [00:28<01:18, 11.54it/s]WARNING:root:Failed to count annotations for vimiv-qt. Exception: Syntax Error @ 9:4.\n",
      "Incomplete input. Unexpectedly encountered '\\n'.\n",
      "\n",
      "for\n",
      "   ^\n",
      " 25%|██▍       | 295/1181 [00:29<00:52, 16.93it/s]WARNING:root:Failed to count annotations for kolla-cli. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for go-site. Exception: Syntax Error @ 38:15.\n",
      "Incomplete input. Encountered '\"set basline\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"set basline\"\n",
      "              ^\n",
      " 25%|██▌       | 299/1181 [00:29<00:51, 17.21it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 26%|██▋       | 311/1181 [00:30<01:02, 14.02it/s]WARNING:root:Failed to count annotations for c2cgeoportal. Exception: Syntax Error @ 5:8.\n",
      "Incomplete input. Encountered '{', but expected 'NAME'.\n",
      "\n",
      "import {{cookiecutter.package}}_geoportal.authentication\n",
      "       ^\n",
      " 27%|██▋       | 318/1181 [00:31<01:23, 10.34it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 28%|██▊       | 332/1181 [00:32<01:06, 12.67it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for nixnet-python. Exception: Syntax Error @ 1:10.\n",
      "Internal error: Must have at least one space after import.\n",
      "\n",
      "﻿import os\n",
      "         ^\n",
      " 30%|██▉       | 354/1181 [00:33<01:10, 11.66it/s]WARNING:root:Failed to count annotations for qtqa. Exception: Syntax Error @ 71:53.\n",
      "Internal error: Must have at least one space after await\n",
      "\n",
      "        projects = await(self.g.list_all_projects())\n",
      "                                                    ^\n",
      "WARNING:root:Failed to count annotations for python-snippets. Exception: Syntax Error @ 3:8.\n",
      "\"'\" is not a valid token.\n",
      "\n",
      "def ^2(' ):\n",
      "       ^\n",
      " 31%|███       | 367/1181 [00:34<01:10, 11.50it/s]WARNING:root:Failed to count annotations for tractor. Exception: Syntax Error @ 76:37.\n",
      "Incomplete input. Encountered 'as', but expected ')'.\n",
      "\n",
      "                trio.open_nursery() as n,\n",
      "                                    ^\n",
      " 34%|███▎      | 396/1181 [00:36<01:03, 12.39it/s]WARNING:root:Failed to count annotations for fat-forensics. Exception: Syntax Error @ 8:64.\n",
      "Internal error: There must be at least one space between 'as' and name.\n",
      "\n",
      "                                                       describe)\n",
      "                                                               ^\n",
      " 34%|███▍      | 400/1181 [00:37<01:41,  7.72it/s]WARNING:root:Failed to count annotations for pipenv-setup. Exception: Syntax Error @ 9:1.\n",
      "Incomplete input. Unexpectedly encountered ')'.\n",
      "\n",
      ")\n",
      "^\n",
      " 34%|███▍      | 405/1181 [00:37<01:06, 11.66it/s]WARNING:root:Failed to count annotations for pymap. Exception: Syntax Error @ 44:50.\n",
      "Incomplete input. Encountered 'as', but expected ')'.\n",
      "\n",
      "        async with (self.catch_errors('GetUser') as result,\n",
      "                                                 ^\n",
      " 37%|███▋      | 442/1181 [00:40<00:48, 15.21it/s]WARNING:root:Failed to count annotations for pulse-data. Exception: division by zero\n",
      " 38%|███▊      | 445/1181 [00:40<00:48, 15.10it/s]WARNING:root:Failed to count annotations for Erasmus. Exception: Syntax Error @ 146:15.\n",
      "Incomplete input. Encountered 'exception', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        match exception:\n",
      "              ^\n",
      " 38%|███▊      | 450/1181 [00:40<00:40, 18.22it/s]WARNING:root:Failed to count annotations for DataModellingTools. Exception: Syntax Error @ 357:58.\n",
      "Incomplete input. Encountered ',', but expected ':'.\n",
      "\n",
      "                        except antlr.RecognitionException, e:\n",
      "                                                         ^\n",
      " 40%|████      | 475/1181 [00:41<00:40, 17.35it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 41%|████      | 486/1181 [00:42<00:26, 26.06it/s]WARNING:root:Failed to count annotations for fantasy-anime-league. Exception: Syntax Error @ 59:15.\n",
      "Incomplete input. Encountered '\"%s -- team/username error\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"%s -- team/username error\" % (team_error)\n",
      "              ^\n",
      " 43%|████▎     | 512/1181 [00:43<00:29, 22.81it/s]WARNING:root:Failed to count annotations for zsh-docker-aliases. Exception: division by zero\n",
      " 44%|████▎     | 516/1181 [00:43<00:26, 25.25it/s]WARNING:root:Failed to count annotations for emacs.d. Exception: division by zero\n",
      " 44%|████▍     | 522/1181 [00:43<00:33, 19.81it/s]WARNING:root:Failed to count annotations for config. Exception: Syntax Error @ 37:1.\n",
      "Inconsistent indentation. Expected a dedent.\n",
      "\n",
      "        try: execfile (file, __main__.__dict__)\n",
      "^\n",
      " 46%|████▌     | 541/1181 [00:45<00:33, 19.32it/s]WARNING:root:Failed to count annotations for ve. Exception: division by zero\n",
      " 46%|████▋     | 547/1181 [00:45<00:39, 16.12it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 52%|█████▏    | 612/1181 [00:49<00:39, 14.31it/s]WARNING:root:Failed to count annotations for ppb-vector. Exception: Syntax Error @ 5:11.\n",
      "Incomplete input. Encountered 'Vector', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "    match Vector(1, 2):\n",
      "          ^\n",
      " 54%|█████▍    | 641/1181 [00:51<00:29, 18.41it/s]WARNING:root:Failed to count annotations for .dotfiles. Exception: division by zero\n",
      " 55%|█████▍    | 648/1181 [00:52<00:34, 15.28it/s]WARNING:root:Failed to count annotations for neuralknight. Exception: division by zero\n",
      " 55%|█████▌    | 650/1181 [00:52<00:37, 14.27it/s]WARNING:root:Failed to count annotations for whatsthis. Exception: division by zero\n",
      " 55%|█████▌    | 655/1181 [00:52<00:30, 17.13it/s]WARNING:root:Failed to count annotations for terraform-aws-api-gateway. Exception: division by zero\n",
      " 56%|█████▋    | 666/1181 [00:53<00:21, 24.10it/s]WARNING:root:Failed to count annotations for snippets. Exception: Syntax Error @ 30:11.\n",
      "Incomplete input. Encountered 'row', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "    print row\n",
      "          ^\n",
      " 58%|█████▊    | 687/1181 [00:53<00:16, 29.45it/s]WARNING:root:Failed to count annotations for LinqPadSnippets. Exception: Syntax Error @ 11:1.\n",
      "Incomplete input. Unexpectedly encountered '%'.\n",
      "\n",
      "%matplotlib\n",
      "^\n",
      "WARNING:root:Failed to count annotations for teleskype. Exception: Syntax Error @ 5:15.\n",
      "Incomplete input. Unexpectedly encountered '/'.\n",
      "\n",
      "python_path = /path/to/teleskype/virtualenv/bin/python\n",
      "              ^\n",
      " 59%|█████▊    | 691/1181 [00:54<00:21, 23.18it/s]WARNING:root:Failed to count annotations for osm-gimmisn. Exception: division by zero\n",
      " 59%|█████▉    | 696/1181 [00:54<00:17, 27.36it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 60%|██████    | 710/1181 [00:55<00:23, 19.71it/s]WARNING:root:Failed to count annotations for homeauto. Exception: Syntax Error @ 15:11.\n",
      "Incomplete input. Encountered \"'reading at %s'\", but expected ';', or 'NEWLINE'.\n",
      "\n",
      "    print 'reading at %s' % root\n",
      "          ^\n",
      " 61%|██████    | 721/1181 [00:55<00:26, 17.09it/s]WARNING:root:Failed to count annotations for eduid-dockerfiles. Exception: division by zero\n",
      " 62%|██████▏   | 728/1181 [00:55<00:20, 21.80it/s]WARNING:root:Failed to count annotations for .emacs.d. Exception: division by zero\n",
      " 63%|██████▎   | 741/1181 [00:57<00:34, 12.81it/s]WARNING:root:Failed to count annotations for curstr.nvim. Exception: division by zero\n",
      " 65%|██████▌   | 768/1181 [00:58<00:20, 20.28it/s]WARNING:root:Failed to count annotations for dot_files. Exception: Syntax Error @ 13:26.\n",
      "Incomplete input. Encountered \"'&\\\\w+?;'\", but expected ')'.\n",
      "\n",
      "_UNESCAPE = re.compile(ur'&\\w+?;', re.UNICODE)\n",
      "                         ^\n",
      " 66%|██████▌   | 778/1181 [00:59<00:20, 19.91it/s]WARNING:root:Failed to count annotations for advent. Exception: Syntax Error @ 53:7.\n",
      "Incomplete input. Encountered 'Counter', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "print Counter(closest_particle)\n",
      "      ^\n",
      " 67%|██████▋   | 793/1181 [00:59<00:16, 23.58it/s]WARNING:root:Failed to count annotations for volatile_thunk. Exception: division by zero\n",
      " 67%|██████▋   | 797/1181 [01:00<00:16, 23.50it/s]WARNING:root:Failed to count annotations for nvim. Exception: division by zero\n",
      " 68%|██████▊   | 802/1181 [01:00<00:16, 22.78it/s]WARNING:root:Failed to count annotations for sostagram. Exception: division by zero\n",
      " 69%|██████▉   | 813/1181 [01:00<00:11, 31.53it/s]WARNING:root:Failed to count annotations for python-stubs. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 69%|██████▉   | 819/1181 [01:00<00:09, 36.97it/s]WARNING:root:Failed to count annotations for zsh-peco-ssh-connect. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for zsh-git-aliases. Exception: division by zero\n",
      " 70%|██████▉   | 825/1181 [01:00<00:08, 39.96it/s]WARNING:root:Failed to count annotations for zsh-pyenv. Exception: division by zero\n",
      " 72%|███████▏  | 848/1181 [01:01<00:09, 34.75it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: Syntax Error @ 5:1.\n",
      "'$' is not a valid token.\n",
      "\n",
      "$HOST = socket.gethostname()\n",
      "^\n",
      "WARNING:root:Failed to count annotations for docker-hugo. Exception: division by zero\n",
      " 72%|███████▏  | 854/1181 [01:01<00:09, 35.35it/s]WARNING:root:Failed to count annotations for luismayta.github.io. Exception: division by zero\n",
      " 73%|███████▎  | 859/1181 [01:01<00:08, 37.15it/s]WARNING:root:Failed to count annotations for zsh-flutter. Exception: division by zero\n",
      " 74%|███████▍  | 875/1181 [01:02<00:12, 23.87it/s]WARNING:root:Failed to count annotations for coding-challenges. Exception: Syntax Error @ 16:11.\n",
      "Incomplete input. Encountered 'array', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "    print array\n",
      "          ^\n",
      "WARNING:root:Failed to count annotations for mfw-template. Exception: Syntax Error @ 3:7.\n",
      "Incomplete input. Encountered '{', but expected 'NAME'.\n",
      "\n",
      "class {{ cookiecutter.behavior_name }}ModelUI(object):\n",
      "      ^\n",
      " 75%|███████▌  | 888/1181 [01:02<00:13, 21.28it/s]WARNING:root:Failed to count annotations for resume. Exception: division by zero\n",
      " 77%|███████▋  | 906/1181 [01:03<00:08, 32.72it/s]WARNING:root:Failed to count annotations for zsh-rvm. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for learning. Exception: Syntax Error @ 5:1.\n",
      "Incomplete input. Encountered a dedent, but expected 'INDENT'.\n",
      "\n",
      "        for j in range(i, len(sequence + 1)):\n",
      "                                             ^\n",
      " 77%|███████▋  | 913/1181 [01:03<00:08, 33.06it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 79%|███████▊  | 929/1181 [01:04<00:08, 30.07it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 80%|███████▉  | 940/1181 [01:04<00:09, 26.41it/s]WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for python-prj-template. Exception: Syntax Error @ 2:6.\n",
      "Incomplete input. Encountered '{', but expected '.', '...', or 'NAME'.\n",
      "\n",
      "from {{cookiecutter.package_name}}.config import GCONFIG\n",
      "     ^\n",
      " 82%|████████▏ | 966/1181 [01:05<00:04, 46.09it/s]WARNING:root:Failed to count annotations for fuzzy-note. Exception: division by zero\n",
      " 82%|████████▏ | 971/1181 [01:05<00:06, 34.61it/s]WARNING:root:Failed to count annotations for WS_THEbotIT. Exception: Syntax Error @ 127:76.\n",
      "Incomplete input. Encountered 'async', but expected ')'.\n",
      "\n",
      "    page.save(summary = 'setzen der Links auf die Seiten', botflag = True, async= True)\n",
      "                                                                           ^\n",
      " 83%|████████▎ | 979/1181 [01:05<00:04, 43.67it/s]WARNING:root:Failed to count annotations for py-docker-template. Exception: division by zero\n",
      " 83%|████████▎ | 985/1181 [01:05<00:04, 45.99it/s]WARNING:root:Failed to count annotations for .vim. Exception: division by zero\n",
      " 84%|████████▍ | 991/1181 [01:05<00:04, 39.09it/s]WARNING:root:Failed to count annotations for terraform-aws-lambda. Exception: division by zero\n",
      " 85%|████████▍ | 1001/1181 [01:06<00:04, 38.22it/s]WARNING:root:Failed to count annotations for watchdodge. Exception: Syntax Error @ 76:1.\n",
      "Incomplete input. Encountered a dedent, but expected 'INDENT'.\n",
      "\n",
      "<<<<<<< HEAD\n",
      "^\n",
      " 86%|████████▌ | 1014/1181 [01:06<00:05, 30.88it/s]WARNING:root:Failed to count annotations for Random. Exception: Syntax Error @ 8:7.\n",
      "Incomplete input. Encountered 'b', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "print b['nikhil']\n",
      "      ^\n",
      " 86%|████████▌ | 1018/1181 [01:06<00:06, 25.39it/s]WARNING:root:Failed to count annotations for mapgen. Exception: division by zero\n",
      " 87%|████████▋ | 1024/1181 [01:07<00:08, 17.78it/s]WARNING:root:Failed to count annotations for drone-pytools. Exception: division by zero\n",
      " 87%|████████▋ | 1029/1181 [01:07<00:07, 21.58it/s]WARNING:root:Failed to count annotations for docker-php. Exception: division by zero\n",
      " 87%|████████▋ | 1033/1181 [01:07<00:06, 23.09it/s]WARNING:root:Failed to count annotations for prometeo. Exception: Syntax Error @ 312:39.\n",
      "Incomplete input. Encountered 'async', but expected ')'.\n",
      "\n",
      "    def visit_FunctionDef(self, node, async=False):\n",
      "                                      ^\n",
      "WARNING:root:Failed to count annotations for snippets. Exception: Syntax Error @ 11:19.\n",
      "Incomplete input. Encountered '\"working\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "            print \"working\"\n",
      "                  ^\n",
      " 89%|████████▉ | 1052/1181 [01:08<00:04, 26.79it/s]WARNING:root:Failed to count annotations for notify-run-deployment. Exception: division by zero\n",
      " 90%|████████▉ | 1057/1181 [01:08<00:04, 28.66it/s]WARNING:root:Failed to count annotations for junk. Exception: Syntax Error @ 29:15.\n",
      "Incomplete input. Encountered '\"getting\"', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "        print \"getting\", name\n",
      "              ^\n",
      " 90%|█████████ | 1065/1181 [01:08<00:03, 31.32it/s]WARNING:root:Failed to count annotations for zsh-tfenv. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for dotfiles. Exception: division by zero\n",
      " 91%|█████████ | 1075/1181 [01:08<00:02, 42.64it/s]WARNING:root:Failed to count annotations for LMS. Exception: Syntax Error @ 5:8.\n",
      "Incomplete input. Encountered 'exercise', but expected ';', or 'NEWLINE'.\n",
      "\n",
      "Normal exercise\n",
      "       ^\n",
      " 93%|█████████▎| 1101/1181 [01:09<00:01, 40.84it/s]WARNING:root:Failed to count annotations for python-playground. Exception: division by zero\n",
      " 94%|█████████▍| 1108/1181 [01:09<00:01, 46.91it/s]WARNING:root:Failed to count annotations for zuul-infra. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for django-project-template. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for zsh-nvm. Exception: division by zero\n",
      " 96%|█████████▌| 1131/1181 [01:10<00:01, 39.11it/s]WARNING:root:Failed to count annotations for sayanarijit.github.io. Exception: division by zero\n",
      " 97%|█████████▋| 1149/1181 [01:10<00:00, 37.52it/s]WARNING:root:Failed to count annotations for snooty. Exception: division by zero\n",
      "WARNING:root:Failed to count annotations for chess. Exception: division by zero\n",
      " 98%|█████████▊| 1156/1181 [01:10<00:00, 29.20it/s]WARNING:root:Failed to count annotations for hab-map-django. Exception: Syntax Error @ 9:70.\n",
      "'\\\\' is not a valid token.\n",
      "\n",
      "        return self.annotate(timestamp=TruncMonth('effective_date')) \\ # Truncate to Day and add to select list\n",
      "                                                                     ^\n",
      "100%|██████████| 1181/1181 [01:17<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/1181 repos have enough portions of type annotations.\n"
     ]
    }
   ],
   "source": [
    "# filter away repos with too few annotations\n",
    "\n",
    "def count_repo_annots(rep):\n",
    "    try:\n",
    "        rep.count_annotations(repos_dir)\n",
    "        if rep.n_type_annots / rep.lines_of_code > 0.05:\n",
    "            return rep\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to count annotations for {rep.name}. Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=30) as executor:\n",
    "    fs = [executor.submit(count_repo_annots, rep) for rep in small_repos]\n",
    "    rs = [f.result() for f in tqdm(as_completed(fs), total=len(fs))]\n",
    "useful_repos: list[GitRepo] = [\n",
    "    r for r in rs if r is not None and \"typeshed\" not in r.name\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"{len(useful_repos)}/{len(small_repos)} repos are parsable and have enough portions of type annotations.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of manual annotations: 343595\n",
      "Total number of type places: 544497\n",
      "Total number of lines of code: 3342911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[GitRepo(author='skorokithakis', name='catt', url='https://github.com/skorokithakis/catt', stars=1740, forks=762, lines_of_code=2036, last_update=datetime.datetime(2022, 4, 10, 1, 30, 43), n_type_annots=140, n_type_places=433),\n",
       " GitRepo(author='encode', name='databases', url='https://github.com/encode/databases', stars=769, forks=48, lines_of_code=3124, last_update=datetime.datetime(2022, 3, 6, 12, 25, 10), n_type_annots=323, n_type_places=498),\n",
       " GitRepo(author='Curt-Park', name='rainbow-is-all-you-need', url='https://github.com/Curt-Park/rainbow-is-all-you-need', stars=490, forks=110, lines_of_code=107, last_update=datetime.datetime(2022, 1, 13, 23, 4, 48), n_type_annots=26, n_type_places=30),\n",
       " GitRepo(author='jreese', name='aiomultiprocess', url='https://github.com/jreese/aiomultiprocess', stars=585, forks=45, lines_of_code=1140, last_update=datetime.datetime(2022, 2, 4, 21, 28, 7), n_type_annots=138, n_type_places=213),\n",
       " GitRepo(author='instaloader', name='instaloader', url='https://github.com/instaloader/instaloader', stars=874, forks=134, lines_of_code=5417, last_update=datetime.datetime(2022, 4, 18, 9, 49, 34), n_type_annots=569, n_type_places=843)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some summary statistics\n",
    "\n",
    "# print total number of manual annotations\n",
    "n_total_annots = sum(rep.n_type_annots for rep in useful_repos)\n",
    "print(\"Total number of manual annotations:\", n_total_annots)\n",
    "\n",
    "# print total number of type places\n",
    "n_total_places = sum(rep.n_type_places for rep in useful_repos)\n",
    "print(\"Total number of type places:\", n_total_places)\n",
    "\n",
    "# print total number of lines of code\n",
    "n_total_lines = sum(rep.lines_of_code for rep in useful_repos)\n",
    "print(\"Total number of lines of code:\", n_total_lines)\n",
    "\n",
    "# print average number of type annotations per line of code excluding projects with more than 1000 lines of code\n",
    "n_avg_annots = (\n",
    "    sum(rep.n_type_annots for rep in useful_repos if rep.lines_of_code < 1000)\n",
    "    / n_total_lines\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GitRepo(author='typeddjango', name='pytest-mypy-plugins', url='https://github.com/typeddjango/pytest-mypy-plugins', stars=12, forks=0, lines_of_code=1039, last_update=datetime.datetime(2022, 4, 18, 23, 25, 40), n_type_annots=155, n_type_places=158), GitRepo(author='jfly', name='jfly.github.io', url='https://github.com/jfly/jfly.github.io', stars=0, forks=0, lines_of_code=650, last_update=datetime.datetime(2022, 4, 12, 8, 23, 39), n_type_annots=39, n_type_places=122), GitRepo(author='seattleflu', name='id3c', url='https://github.com/seattleflu/id3c', stars=2, forks=0, lines_of_code=8883, last_update=datetime.datetime(2022, 4, 21, 15, 38, 59), n_type_annots=675, n_type_places=1068)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "useful_repos_path = proj_root() / \"scripts\" / \"useful_repos.pkl\"\n",
    "with useful_repos_path.open(\"wb\") as f:\n",
    "    pickle.dump(useful_repos, f)\n",
    "print(f\"Saved {len(useful_repos)} useful repos to {useful_repos_path}.\")\n",
    "with useful_repos_path.open(\"rb\") as f:\n",
    "    print(pickle.load(f)[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run form here: Analyzing src datasets.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "from spot import proj_root\n",
    "from spot.data import TokenizedSrcSet, get_data_dir, get_datasets_name, PreprocessArgs\n",
    "import spot.function_dataset as fd\n",
    "from spot.utils import Path, run_long_task, DefaultTokenizer, not_none\n",
    "import subprocess\n",
    "\n",
    "repos_split_path = proj_root() /  \"data/repos_split.pkl\"\n",
    "repos_dir = get_data_dir() / \"SPOT-data/repos/\"\n",
    "\n",
    "recreate = False\n",
    "func_only = True\n",
    "pre_args = PreprocessArgs(\n",
    "    drop_env_types=True,\n",
    "    stub_in_preamble=True,\n",
    ")\n",
    "data_reduction = 1\n",
    "\n",
    "datasets_name = get_datasets_name(\n",
    "    pre_args, func_only, data_reduction=data_reduction,\n",
    ")\n",
    "datasets_path = get_data_dir() / \"SPOT-data\" / datasets_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: Generating TokenizedSrcSets: func_datasets-v5-PreprocessArgs(drop_env_types=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset from repos: 100%|██████████| 573/573 [08:02<00:00,  1.19it/s]\n",
      "Generating dataset from repos: 100%|██████████| 40/40 [02:12<00:00,  3.32s/it]\n",
      "Generating dataset from repos: 100%|██████████| 50/50 [01:32<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved source datasets to: /mnt/data0/jiayi/SPOT-data/func_datasets-v5-PreprocessArgs(drop_env_types=False)\n",
      "777M\t/mnt/data0/jiayi/SPOT-data/func_datasets-v5-PreprocessArgs(drop_env_types=False)\n",
      "Pushover: (Finished: 'Generating TokenizedSrcSets: func_datasets-v5-PreprocessArgs(drop_env_types=False)'.) Time taken: 736.9s\n"
     ]
    }
   ],
   "source": [
    "from spot.data import create_tokenized_srcsets, load_tokenized_srcsets\n",
    "if recreate or not datasets_path.exists():\n",
    "    create_tokenized_srcsets(\n",
    "        proj_root() / \"data/repos_split.pkl\",\n",
    "        datasets_path,\n",
    "        func_only=func_only,\n",
    "        pre_args=pre_args,\n",
    "        data_reduction=data_reduction,\n",
    "    )\n",
    "tk_dataset = load_tokenized_srcsets(\n",
    "    datadir,\n",
    "    datasets_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from pandas import DataFrame\n",
    "\n",
    "from spot.utils import cumulative_counts\n",
    "\n",
    "len_counts = [len(src.tokenized_code) for src in tk_dataset[\"train\"].all_srcs]\n",
    "xs, ys = cumulative_counts(len_counts)\n",
    "px.line(\n",
    "    DataFrame({\"tokens_per_file\": xs, \"n_files\": ys}), x=\"tokens_per_file\", y=\"n_files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: /mnt/data0/jiayi/SPOT-data/func_datasets-v5-PreprocessArgs(drop_env_types=False)\n",
      "num_repos: 572\n",
      "num_files: 134977\n",
      "num_lines: 5752662\n",
      "num_labels: 293592\n",
      "main_tokens_per_file:\n",
      "   mean: 1578.6\n",
      "   median: 717\n",
      "   min: 17\n",
      "   max: 97666\n",
      "preamble_tokens_per_file:\n",
      "   mean: 196.41\n",
      "   median: 134\n",
      "   min: 2\n",
      "   max: 6729\n",
      "target_tks_per_file:\n",
      "   mean: 7.8197\n",
      "   median: 5\n",
      "   min: 2\n",
      "   max: 725\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset:\", datasets_path)\n",
    "tk_dataset[\"train\"].print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: /mnt/data0/jiayi/SPOT-data/func_datasets-v4-PreprocessArgs(drop_env_types=False)\n",
      "num_repos: 572\n",
      "num_files: 134977\n",
      "num_lines: 16579520\n",
      "num_labels: 293592\n",
      "main_tokens_per_file:\n",
      "   mean: 1585\n",
      "   median: 717\n",
      "   min: 17\n",
      "   max: 94019\n",
      "preamble_tokens_per_file:\n",
      "   mean: 970.94\n",
      "   median: 532\n",
      "   min: 6\n",
      "   max: 49334\n",
      "target_tks_per_file:\n",
      "   mean: 7.8197\n",
      "   median: 5\n",
      "   min: 2\n",
      "   max: 725\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset:\", datasets_path)\n",
    "tk_dataset[\"train\"].print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.data import load_tokenized_srcsets\n",
    "\n",
    "# tk_dataset = load_tokenized_srcsets(get_data_dir(), get_dataset_name(pre_args, func_only))\n",
    "\n",
    "long_files=sorted(tk_dataset[\"train\"].all_srcs, key=lambda s: len(s.tokenized_code),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fastapi import FastAPI\n",
      "from pydantic import BaseModel\n",
      "from fastapi.responses import JSONResponse\n",
      "class Item(BaseModel):\n",
      "    ...\n",
      "class Message(BaseModel):\n",
      "    ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(long_files[8].preamble_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========TokenizedSrc========\n",
      "file:devonhollowood__adventofcode/2018.day10/Point.velocity\n",
      "repo:devonhollowood__adventofcode\n",
      "--------Preamble--------\n",
      "import argparse\n",
      "import re\n",
      "import typing\n",
      "import unittest\n",
      "from functools import lru_cache\n",
      "from dataclasses import dataclass\n",
      "@dataclass(...)\n",
      "class Vector:\n",
      "    x: ...\n",
      "    y: ...\n",
      "@dataclass(...)\n",
      "class Point:\n",
      "    position: ...\n",
      "    velocity: ...\n",
      "    def step(self): ...\n",
      "    velocity: ...\n",
      "    position: ...\n",
      "def bounding_circumference(points): ...\n",
      "@lru_cache(...)\n",
      "def run_until_compact(points): ...\n",
      "@lru_cache(...)\n",
      "def parse(puzzle): ...\n",
      "def part1(puzzle): ...\n",
      "def part2(puzzle): ...\n",
      "def main(): ...\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "class ExampleTest(unittest.TestCase):\n",
      "    example = ...\n",
      "    expected = ...\n",
      "    def test_part1(self): ...\n",
      "    def test_part2(self): ...\n",
      "    example: ...\n",
      "    assertEqual: ...\n",
      "    expected: ...\n",
      "\n",
      "--------Main Code--------\n",
      "\n",
      "# BEGIN\n",
      "\n",
      "# 2018.day10\n",
      "@dataclass(frozen=True)\n",
      "class Point:\n",
      "    velocity: <mask>\n",
      "\n",
      "# END\n",
      "\n",
      "# 2018.day10\n",
      "@lru_cache()\n",
      "def parse(puzzle: str) -> typing.FrozenSet[Point]:\n",
      "    line_re = re.compile(\n",
      "        r'position=<\\s*(?P<x>-?\\d+),\\s*(?P<y>-?\\d+)> velocity=<\\s*(?P<vx>-?\\d+),\\s*(?P<vy>-?\\d+)>')\n",
      "    points = []\n",
      "    for line in puzzle.splitlines():\n",
      "        match = line_re.match(line)\n",
      "        if not match:\n",
      "            raise ValueError('Bad input line:'+ line)\n",
      "        points.append(Point(\n",
      "            position=Vector(x=int(match['x']), y=int(match['y'])),\n",
      "            velocity=Vector(x=int(match['vx']), y=int(match['vy']))))\n",
      "    return frozenset(points)\n",
      "\n",
      "\n",
      "# 2018.day10\n",
      "@dataclass(frozen=True)\n",
      "class Point:\n",
      "\n",
      "    def step(self) -> 'Point':\n",
      "        return Point(\n",
      "            position=Vector(x=self.position.x + self.velocity.x,\n",
      "                            y=self.position.y + self.velocity.y),\n",
      "            velocity=self.velocity)\n",
      "    \n",
      "\n",
      "\n",
      "========End of TokenizedSrc========\n"
     ]
    }
   ],
   "source": [
    "print(str(tk_dataset[\"train\"].all_srcs[2345]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# fastapi.routing/APIRouter\n",
      "def api_route(\n",
      "    self,\n",
      "    path,\n",
      "    *,\n",
      "    response_model = None,\n",
      "    status_code = None,\n",
      "    tags = None,\n",
      "    dependencies = None,\n",
      "    summary = None,\n",
      "    description = None,\n",
      "    response_description = \"Successful Response\",\n",
      "    responses = None,\n",
      "    deprecated = None,\n",
      "    methods = None,\n",
      "    operation_id = None,\n",
      "    response_model_include = None,\n",
      "    response_model_exclude = None,\n",
      "    response_model_by_alias = True,\n",
      "    response_model_exclude_unset = False,\n",
      "    response_model_exclude_defaults = False,\n",
      "    response_model_exclude_none = False,\n",
      "    include_in_schema = True,\n",
      "    response_class = Default(JSONResponse),\n",
      "    name = None,\n",
      "    callbacks = None,\n",
      "    openapi_extra = None,\n",
      "    generate_unique_id_function = Default(\n",
      "        generate_unique_id\n",
      "    ),\n",
      "):\n",
      "    def decorator(func):\n",
      "        self.add_api_route(\n",
      "            path,\n",
      "            func,\n",
      "            response_model=response_model,\n",
      "            status_code=status_code,\n",
      "            tags=tags,\n",
      "            dependencies=dependencies,\n",
      "            summary=summary,\n",
      "            description=description,\n",
      "            response_description=response_description,\n",
      "            responses=responses,\n",
      "            deprecated=deprecated,\n",
      "            methods=methods,\n",
      "            operation_id=operation_id,\n",
      "            response_model_include=response_model_include,\n",
      "            response_model_exclude=response_model_exclude,\n",
      "            response_model_by_alias=response_model_by_alias,\n",
      "            response_model_exclude_unset=response_model_exclude_unset,\n",
      "            response_model_exclude_defaults=response_model_exclude_defaults,\n",
      "            response_model_exclude_none=response_model_exclude_none,\n",
      "            include_in_schema=include_in_schema,\n",
      "            response_class=response_class,\n",
      "            name=name,\n",
      "            callbacks=callbacks,\n",
      "            openapi_extra=openapi_extra,\n",
      "            generate_unique_id_function=generate_unique_id_function,\n",
      "        )\n",
      "        return func\n",
      "\n",
      "    return decorator\n",
      "# fastapi.datastructures\n",
      "def Default(value):\n",
      "    return DefaultPlaceholder(value)  \n",
      "# fastapi.routing/APIRouter\n",
      "def get(\n",
      "    self,\n",
      "    path: <mask>,\n",
      "    *,\n",
      "    response_model: <mask> = None,\n",
      "    status_code: <mask> = None,\n",
      "    tags: <mask> = None,\n",
      "    dependencies: <mask> = None,\n",
      "    summary: <mask> = None,\n",
      "    description: <mask> = None,\n",
      "    response_description: <mask> = \"Successful Response\",\n",
      "    responses: <mask> = None,\n",
      "    deprecated: <mask> = None,\n",
      "    operation_id: <mask> = None,\n",
      "    response_model_include: <mask> = None,\n",
      "    response_model_exclude: <mask> = None,\n",
      "    response_model_by_alias: <mask> = True,\n",
      "    response_model_exclude_unset: <mask> = False,\n",
      "    response_model_exclude_defaults: <mask> = False,\n",
      "    response_model_exclude_none: <mask> = False,\n",
      "    include_in_schema: <mask> = True,\n",
      "    response_class: <mask> = Default(JSONResponse),\n",
      "    name: <mask> = None,\n",
      "    callbacks: <mask> = None,\n",
      "    openapi_extra: <mask> = None,\n",
      "    generate_unique_id_function: <mask> = Default(\n",
      "        generate_unique_id\n",
      "    ),\n",
      ") -> <mask>:\n",
      "    return self.api_route(\n",
      "        path=path,\n",
      "        response_model=response_model,\n",
      "        status_code=status_code,\n",
      "        tags=tags,\n",
      "        dependencies=dependencies,\n",
      "        summary=summary,\n",
      "        description=description,\n",
      "        response_description=response_description,\n",
      "        responses=responses,\n",
      "        deprecated=deprecated,\n",
      "        methods=[\"GET\"],\n",
      "        operation_id=operation_id,\n",
      "        response_model_include=response_model_include,\n",
      "        response_model_exclude=response_model_exclude,\n",
      "        response_model_by_alias=response_model_by_alias,\n",
      "        response_model_exclude_unset=response_model_exclude_unset,\n",
      "        response_model_exclude_defaults=response_model_exclude_defaults,\n",
      "        response_model_exclude_none=response_model_exclude_none,\n",
      "        include_in_schema=include_in_schema,\n",
      "        response_class=response_class,\n",
      "        name=name,\n",
      "        callbacks=callbacks,\n",
      "        openapi_extra=openapi_extra,\n",
      "        generate_unique_id_function=generate_unique_id_function,\n",
      "    )\n",
      "# tests.test_validate_response\n",
      "def test_invalid():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/invalid\")\n",
      "# tests.test_skip_defaults\n",
      "def test_return_defaults():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.json() == {\"sub\": {}}\n",
      "# tests.test_validate_response\n",
      "def test_double_invalid():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/innerinvalid\")\n",
      "# tests.test_validate_response\n",
      "def test_invalid_list():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/invalidlist\")\n",
      "# tests.test_validate_response_dataclass\n",
      "def test_invalid():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/invalid\")\n",
      "# tests.test_skip_defaults\n",
      "def test_return_exclude_defaults():\n",
      "    response = client.get(\"/exclude_defaults\")\n",
      "    assert response.json() == {}\n",
      "# tests.test_openapi_servers\n",
      "def test_app():\n",
      "    response = client.get(\"/foo\")\n",
      "    assert response.status_code == 200, response.text\n",
      "# tests.test_additional_responses_bad\n",
      "def test_openapi_schema():\n",
      "    with pytest.raises(ValueError):\n",
      "        client.get(\"/openapi.json\")\n",
      "# tests.test_validate_response_dataclass\n",
      "def test_double_invalid():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/innerinvalid\")\n",
      "# tests.test_validate_response_dataclass\n",
      "def test_invalid_list():\n",
      "    with pytest.raises(ValidationError):\n",
      "        client.get(\"/items/invalidlist\")\n",
      "# tests.test_tutorial.test_websockets.test_tutorial003\n",
      "def test_get():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.text == html\n",
      "# tests.test_no_swagger_ui_redirect\n",
      "def test_response():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.json() == {\"id\": \"foo\"}\n",
      "# tests.test_custom_swagger_ui_redirect\n",
      "def test_response():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.json() == {\"id\": \"foo\"}\n",
      "# tests.test_swagger_ui_init_oauth\n",
      "def test_response():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.json() == {\"id\": \"foo\"}\n",
      "# tests.test_exception_handlers\n",
      "def test_override_server_error_exception_raises():\n",
      "    with pytest.raises(RuntimeError):\n",
      "        client.get(\"/server-error\")\n",
      "# docs_src.sql_databases_peewee.sql_app.database/PeeweeConnectionState\n",
      "def __getattr__(self, name):\n",
      "    return self._state.get()[name]\n",
      "# tests.test_param_in_path_and_dependency\n",
      "def test_read_users():\n",
      "    response = client.get(\"/users/42\")\n",
      "    assert response.status_code == 200, response.text\n",
      "# tests.test_skip_defaults\n",
      "def test_return_exclude_unset_none():\n",
      "    response = client.get(\"/exclude_unset_none\")\n",
      "    assert response.json() == {\"y\": \"y\"}\n",
      "# tests.test_skip_defaults\n",
      "def test_return_exclude_unset():\n",
      "    response = client.get(\"/exclude_unset\")\n",
      "    assert response.json() == {\"x\": None, \"y\": \"y\"}\n",
      "# tests.test_path\n",
      "def test_text_get():\n",
      "    response = client.get(\"/text\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == \"Hello World\"\n",
      "# docs_src.sql_databases_peewee.sql_app.database/PeeweeConnectionState\n",
      "def __setattr__(self, name, value):\n",
      "    self._state.get()[name] = value\n",
      "# tests.test_skip_defaults\n",
      "def test_return_exclude_none():\n",
      "    response = client.get(\"/exclude_none\")\n",
      "    assert response.json() == {\"y\": \"y\", \"z\": \"z\"}\n",
      "# tests.test_openapi_route_extensions\n",
      "def test_get_route():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {}\n",
      "# tests.test_additional_responses_router\n",
      "def test_a():\n",
      "    response = client.get(\"/a\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == \"a\"\n",
      "# tests.test_additional_responses_router\n",
      "def test_b():\n",
      "    response = client.get(\"/b\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == \"b\"\n",
      "# tests.test_additional_responses_router\n",
      "def test_c():\n",
      "    response = client.get(\"/c\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == \"c\"\n",
      "# tests.test_http_connection_injection\n",
      "def test_value_extracting_by_http():\n",
      "    response = client.get(\"/http\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == 42\n",
      "# tests.test_param_in_path_and_dependency\n",
      "def test_reused_param():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    data = response.json()\n",
      "    assert data == openapi_schema\n",
      "# tests.test_dependency_contextvars\n",
      "def test_dependency_contextvars():\n",
      "    response = client.get(\"/user\")\n",
      "    assert response.json() == \"deadpond\"\n",
      "    assert response.headers[\"custom\"] == \"foo\"\n",
      "# tests.test_deprecated_openapi_prefix\n",
      "@app.get(\"/app\")\n",
      "def read_main(request):\n",
      "    return {\"message\": \"Hello World\", \"root_path\": request.scope.get(\"root_path\")}\n",
      "# tests.test_deprecated_openapi_prefix\n",
      "def test_openapi():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_callable_endpoint\n",
      "def test_partial():\n",
      "    response = client.get(\"/?q=bar\")\n",
      "    data = response.json()\n",
      "    assert data == {\"some_arg\": \"foo\", \"q\": \"bar\"}\n",
      "# tests.test_tuples\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_path\n",
      "def test_nonexistent():\n",
      "    response = client.get(\"/nonexistent\")\n",
      "    assert response.status_code == 404, response.text\n",
      "    assert response.json() == {\"detail\": \"Not Found\"}\n",
      "# tests.test_tutorial.test_path_operation_advanced_configurations.test_tutorial005\n",
      "def test_get():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "# tests.test_dependency_duplicates\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_no_swagger_ui_redirect\n",
      "def test_swagger_ui_no_oauth2_redirect():\n",
      "    response = client.get(\"/docs/oauth2-redirect\")\n",
      "    assert response.status_code == 404, response.text\n",
      "# tests.test_include_route\n",
      "def test_sub_router():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"hello\": \"world\"}\n",
      "# tests.test_extra_routes\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# docs_src.app_testing.test_main\n",
      "def test_read_main():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == {\"msg\": \"Hello World\"}\n",
      "# docs_src.app_testing.tutorial001\n",
      "def test_read_main():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == {\"msg\": \"Hello World\"}\n",
      "# tests.test_security_oauth2\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_exception_handlers\n",
      "def test_override_http_exception():\n",
      "    response = client.get(\"/http-exception\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == {\"exception\": \"http-exception\"}\n",
      "# tests.test_additional_properties\n",
      "def test_additional_properties_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_openapi_route_extensions\n",
      "def test_openapi():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_openapi_servers\n",
      "def test_openapi_servers():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_custom_schema_fields\n",
      "def test_response():\n",
      "    response = client.get(\"/foo\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"name\": \"Foo item\"}\n",
      "# tests.test_tutorial.test_generate_clients.test_tutorial003\n",
      "def test_openapi():\n",
      "    with client:\n",
      "        response = client.get(\"/openapi.json\")\n",
      "\n",
      "        assert response.json() == openapi_schema\n",
      "# docs_src.behind_a_proxy.tutorial002\n",
      "@app.get(\"/app\")\n",
      "def read_main(request):\n",
      "    return {\"message\": \"Hello World\", \"root_path\": request.scope.get(\"root_path\")}\n",
      "# docs_src.behind_a_proxy.tutorial003\n",
      "@app.get(\"/app\")\n",
      "def read_main(request):\n",
      "    return {\"message\": \"Hello World\", \"root_path\": request.scope.get(\"root_path\")}\n",
      "# docs_src.behind_a_proxy.tutorial001\n",
      "@app.get(\"/app\")\n",
      "def read_main(request):\n",
      "    return {\"message\": \"Hello World\", \"root_path\": request.scope.get(\"root_path\")}\n",
      "# docs_src.behind_a_proxy.tutorial004\n",
      "@app.get(\"/app\")\n",
      "def read_main(request):\n",
      "    return {\"message\": \"Hello World\", \"root_path\": request.scope.get(\"root_path\")}\n",
      "# tests.test_put_no_body\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_http_base\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_additional_response_extra\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_additional_response_extra\n",
      "def test_path_operation():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"id\": \"foo\"}\n",
      "# tests.test_security_openid_connect\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_param_include_in_schema\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == openapi_shema\n",
      "# tests.test_starlette_exception\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_application\n",
      "def test_enum_status_code_response():\n",
      "    response = client.get(\"/enum-status-code\")\n",
      "    assert response.status_code == 201, response.text\n",
      "    assert response.json() == \"foo bar\"\n",
      "# tests.test_security_http_digest\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_multi_body_errors\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_get_request_body\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_multi_query_errors\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_response_by_alias\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_response_by_alias\n",
      "def test_read_dict():\n",
      "    response = client.get(\"/dict\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"name\": \"Foo\"}\n",
      "# tests.test_response_by_alias\n",
      "def test_read_model():\n",
      "    response = client.get(\"/model\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"name\": \"Foo\"}\n",
      "# tests.test_param_class\n",
      "def test_default_param_query_none():\n",
      "    response = client.get(\"/items/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == {\"q\": None}\n",
      "# tests.test_schema_extra_examples\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_additional_responses_router\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_tutorial.test_sql_databases.test_sql_databases\n",
      "def test_inexistent_user(client):\n",
      "    response = client.get(\"/users/999\")\n",
      "    assert response.status_code == 404, response.text\n",
      "# tests.test_security_http_bearer\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_duplicate_models_openapi\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_oauth2_optional\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_tutorial.test_custom_response.test_tutorial005\n",
      "def test_get():\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.text == \"Hello World\"\n",
      "# tests.test_response_code_no_body\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_additional_responses_response_class\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_api_key_cookie\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_http_base_description\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_http_basic_optional\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_openid_connect_optional\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "    assert response.status_code == 200, response.text\n",
      "    assert response.json() == openapi_schema\n",
      "# tests.test_security_http_base_optional\n",
      "def test_openapi_schema():\n",
      "    response = client.get(\"/openapi.json\")\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "max(tk_dataset[\"train\"].all_srcs, key=lambda s: len(s.tokenized_code)).print_code(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_repos: 572\n",
      "num_files: 16281\n",
      "num_lines: 2698669\n",
      "num_labels: 295457\n",
      "main_tokens_per_file:\n",
      "   mean: 1311.6\n",
      "   median: 608\n",
      "   min: 8\n",
      "   max: 55437\n",
      "preamble_tokens_per_file:\n",
      "   mean: 301.97\n",
      "   median: 181\n",
      "   min: 6\n",
      "   max: 9784\n",
      "target_tks_per_file:\n",
      "   mean: 65.318\n",
      "   median: 28\n",
      "   min: 2\n",
      "   max: 3798\n",
      "n_files_too_wide: 444\n",
      "too_wide_ratio: 0.014897\n",
      "preprocess: PreprocessArgs(imports_in_preamble=True, stub_in_preamble=True, drop_comments=True)\n"
     ]
    }
   ],
   "source": [
    "tk_dataset[\"train\"].print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preamble_len(src):\n",
    "    return len(src.preamble_code.split(\"\\n\"))\n",
    "\n",
    "\n",
    "weird_src = max(tk_dataset[\"train\"].all_srcs, key=preamble_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TokenizedSrcSets:  /mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs()\n",
      "258M\t/mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs()\n"
     ]
    }
   ],
   "source": [
    "from spot.data import load_tokenized_srcsets, get_dataroot\n",
    "\n",
    "sdata_path = get_dataroot() / \"TokenizedSrcSets\" / \"ManyTypes4Py-v5-PreprocessArgs()\"\n",
    "\n",
    "tk_dataset = load_tokenized_srcsets(sdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_repos: 50\n",
      "num_files: 949\n",
      "num_lines: 139121\n",
      "num_labels: 17740\n",
      "main_tokens_per_file:\n",
      "   mean: 1270.5\n",
      "   median: 632\n",
      "   min: 23\n",
      "   max: 57953\n",
      "preamble_tokens_per_file:\n",
      "   mean: 103.8\n",
      "   median: 67\n",
      "   min: 2\n",
      "   max: 1517\n",
      "target_tks_per_file:\n",
      "   mean: 72.285\n",
      "   median: 32\n",
      "   min: 2\n",
      "   max: 1882\n",
      "n_files_too_wide: 1\n",
      "too_wide_ratio: 0.00062735\n",
      "preprocess: PreprocessArgs(imports_in_preamble=True, stub_in_preamble=True, drop_comments=True, max_callees=80, max_callers=20, drop_env_types=True, add_override_usages=False)\n"
     ]
    }
   ],
   "source": [
    "tk_dataset[\"test\"].print_stats()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
