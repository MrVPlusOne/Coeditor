{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from coeditor.common import *\n",
    "import os\n",
    "\n",
    "from coeditor.encoding import encode_basic, decode_tokens\n",
    "import torch\n",
    "from coeditor.retrieval_model import (\n",
    "    RetrievalEditorModel,\n",
    "    T5LayerSelfAttention,\n",
    "    t5_cross_attention,\n",
    "    T5Stack,\n",
    "    encode_query_stack,\n",
    ")\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetrievalEditorModel.from_code_t5(\"base\")\n",
    "device = torch.device(\"cuda:2\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"num_parameters: {model.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test self attention\n",
    "config = model.config\n",
    "sa = T5LayerSelfAttention(config, has_relative_attention_bias=True)\n",
    "sa = sa.to(device)\n",
    "sa.eval()\n",
    "\n",
    "hidden_states = torch.randn(2, 3, config.d_model).to(device)\n",
    "out1 = sa.forward(hidden_states)[0]\n",
    "out2 = t5_cross_attention(sa, hidden_states, key_value_states=hidden_states)[0]\n",
    "\n",
    "torch.all(out1 == out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = model.encoder\n",
    "stack.eval()\n",
    "\n",
    "query_ids = torch.LongTensor([[1, 2, 5], [8, 3, 0]]).to(device)\n",
    "query_mask = query_ids.ne(0)\n",
    "ref_states = tuple(torch.randn(2, 5, config.d_model).to(device) for _ in stack.block)\n",
    "\n",
    "\n",
    "ref_mask = torch.zeros(2, 5, dtype=torch.bool).to(device)\n",
    "out1 = stack.forward(query_ids, attention_mask=query_mask)[0]\n",
    "out2 = encode_query_stack(\n",
    "    stack,\n",
    "    query_ids,\n",
    "    ref_states,\n",
    "    ref_attention_mask=ref_mask,\n",
    ").last_hidden_state\n",
    "\n",
    "print(f\"{out1.dtype=}\")\n",
    "torch.max(torch.abs((out1 - out2) * query_mask.unsqueeze(-1))) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    \"<s>assert weather == <extra_id_0>\\n</s>\",\n",
    "    \"<s>assert time == <extra_id_0> # make this longer\\n</s>\",\n",
    "    \"<s>assert name == <extra_id_0>\\n</s>\",\n",
    "]\n",
    "good_refs = [\n",
    "    \"<s>weather = 'Icey'\\n</s>\",\n",
    "    \"<s>time = '1:25AM'\\n</s>\",\n",
    "    \"<s>name = 'Tako'\\n</s>\",\n",
    "]\n",
    "bad_refs = [\n",
    "    \"<s>weather = 'Sunny'\\n</s>\",\n",
    "    \"<s>time = '5:21PM'\\n</s>\",\n",
    "    \"<s>name = 'Shmi'\\n</s>\",\n",
    "]\n",
    "answer = [\n",
    "    \"<pad><s><extra_id_0>'Icey'\",\n",
    "    \"<pad><s><extra_id_0>'1:25AM'\",\n",
    "    \"<pad><s><extra_id_0>'Tako'\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for q_id in [0]:\n",
    "    q_ids = slice(0, 2)\n",
    "    print(f\"{q_id=}\")\n",
    "    for query_attened_ref in [False, True]:\n",
    "        print(f\"{query_attened_ref=}\")\n",
    "        model.query_attened_ref = query_attened_ref\n",
    "\n",
    "        out = model.forward(\n",
    "            model.encode_token_seqs(query[q_ids]),\n",
    "            references=[encode_basic(x) for x in good_refs],\n",
    "            labels=model.encode_token_seqs(answer[q_ids], -100),\n",
    "        )\n",
    "        print(\"Loss with good ref:\", out.loss.item())\n",
    "\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            out = model.forward(\n",
    "                model.encode_token_seqs(query[q_ids]),\n",
    "                references=[encode_basic(x) for x in reversed(good_refs)],\n",
    "                # query_ref_list=[[1, 0], []],\n",
    "                labels=model.encode_token_seqs(answer[q_ids], -100),\n",
    "            )\n",
    "            print(\"Loss with reversed good ref:\", out.loss.item())\n",
    "\n",
    "        out = model.forward(\n",
    "            model.encode_token_seqs(query[q_ids]),\n",
    "            references=[encode_basic(x) for x in bad_refs],\n",
    "            labels=model.encode_token_seqs(answer[q_ids], -100),\n",
    "        )\n",
    "        print(\"Loss with bad ref:\", out.loss.item())\n",
    "\n",
    "        out = model.forward(\n",
    "            model.encode_token_seqs(query[q_ids]),\n",
    "            references=None,\n",
    "            labels=model.encode_token_seqs(answer[q_ids], -100),\n",
    "        )\n",
    "        print(\"Loss with no ref:\", out.loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coeditor.model import CodeT5Model\n",
    "\n",
    "single_inputs = [\"\".join([*good_refs, q]) for q in query]\n",
    "print(\"Single input:\")\n",
    "print(\"\\n-------\\n\".join(single_inputs))\n",
    "\n",
    "codet5 = cast(CodeT5Model, CodeT5Model.from_pretrained(\"Salesforce/codet5-base\"))\n",
    "codet5.to(device)\n",
    "codet5.eval()\n",
    "\n",
    "out = codet5.forward(\n",
    "    model.encode_token_seqs(single_inputs),\n",
    "    labels=model.encode_token_seqs(answer),\n",
    ")\n",
    "print(\"Loss of CodeT5:\", out.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codet5_seq = codet5.generate(\n",
    "    model.encode_token_seqs(single_inputs),\n",
    "    max_length=50,\n",
    "    num_beams=8,\n",
    ")\n",
    "for i, y in enumerate(codet5_seq):\n",
    "    print(f\"Output {i}:\")\n",
    "    print(decode_tokens(y))\n",
    "\n",
    "model.query_attened_ref = True\n",
    "out_seq = model.generate(\n",
    "    model.encode_token_seqs(query),\n",
    "    references=[encode_basic(x) for x in reversed(good_refs)],\n",
    "    # num_beams=8,\n",
    "    max_length=50,\n",
    ")\n",
    "for i, y in enumerate(out_seq):\n",
    "    print(f\"Output {i}:\")\n",
    "    print(decode_tokens(y))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
