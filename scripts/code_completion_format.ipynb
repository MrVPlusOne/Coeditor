{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from coeditor.common import *\n",
    "import os\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to extract code completion problems from real code changes. Let's start by picking 4 random commits from the history of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommitInfo(hash='84cfd5206348ecc3f54d202b830f803d8a03f26f', parents=('a1e2b73ab836924d0b1f9ed88e4fd90e7a6f61e6',), msg='Add ablation: dense attention.')\n",
      "CommitInfo(hash='a1e2b73ab836924d0b1f9ed88e4fd90e7a6f61e6', parents=('ecdbdc3875e47887ff3c0320fd1367af28d0a491',), msg='Implement ablation: current_code_only.')\n",
      "CommitInfo(hash='ecdbdc3875e47887ff3c0320fd1367af28d0a491', parents=('ad918b35e2b8314f30a7f8ffc1e957c9f49956df',), msg='Exclude builtins defs in ctx by default.')\n"
     ]
    }
   ],
   "source": [
    "from coeditor.git import get_commit_history, CommitInfo\n",
    "\n",
    "repo_root = proj_root()\n",
    "\n",
    "commits = get_commit_history(repo_root, 4, commit_id=\"84cfd5206348ecc3f54d202b830f803d8a03f26f\")\n",
    "for c in commits[:3]:\n",
    "    print(c)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then extract `FIMProblem` instances from these commits using `edits_from_commit_history` function by specifying `C3CompletionGenerator` as the change_processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building initial project: 100%|██████████| 34/34 [00:00<00:00, 45.07it/s]\n",
      "processing commits: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(fim_problems) = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from coeditor.scoped_changes import edits_from_commit_history\n",
    "from coeditor.experiments.code_completion import FIMProblem, C3CompletionGenerator\n",
    "\n",
    "generator = C3CompletionGenerator()\n",
    "\n",
    "workdir = proj_root() / \"../temp-1\"\n",
    "fim_problems = edits_from_commit_history(\n",
    "    repo_root, commits, workdir, change_processor=generator\n",
    ")\n",
    "print(f\"{len(fim_problems) = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize an example problem by first converting it into the input-output format used by CodeT5. Each problem instance asks the model to predict a missing line extracted that correspond to the last added line from the actual changes made to a given code region. Note that in this format, any previous changes made by the user are directly applied to the code that surrounds the missing line.\n",
    "\n",
    "Feel free to change `ex_id` to see other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "output:\n",
      "<s><extra_id_0>                seg = seg + origin_line + [Newline_id]</s>\n",
      "--------------------------------------------------------------------------------\n",
      "input:\n",
      "<s>        if add_bos and sec:\n",
      "            sec[0] = BOS_id\n",
      "    else:\n",
      "        assert_eq(direction, TruncateAt.Right)\n",
      "        if inplace:\n",
      "            del sec[limit:]\n",
      "        else:\n",
      "            sec = sec[:limit]\n",
      "        if add_bos and sec:\n",
      "            sec[-1] = EOS_id\n",
      "    return sec\n",
      "\n",
      "def truncate_sections(\n",
      "    total_limit: int,\n",
      "    *sections: tuple[TokenSeq, TruncateAt.Value],\n",
      "    add_bos: bool,\n",
      "    inplace: bool = False,\n",
      ") -> tuple[TokenSeq,...]:\n",
      "    \"\"\"Truncate a list of token sequences to fit within a total length limit.\n",
      "    Earlier sections have priority over later sections.\n",
      "    \"\"\"\n",
      "\n",
      "    # first, reserve equal space to each section\n",
      "    section_lens = [total_limit // len(sections) for _ in sections]\n",
      "    remaining = total_limit\n",
      "    for i, (tks, _) in enumerate(sections):\n",
      "        l = min(len(tks), section_lens[i])\n",
      "        remaining -= l\n",
      "        section_lens[i] = l\n",
      "    assert remaining >= 0\n",
      "\n",
      "    # for the unused space, assign to ealier sections when possible\n",
      "    for i, (tks, _) in enumerate(sections):\n",
      "        if remaining <= 0:\n",
      "            break\n",
      "        inc = min(remaining, len(tks) - section_lens[i])\n",
      "        section_lens[i] += inc\n",
      "        remaining -= inc\n",
      "\n",
      "    return tuple(\n",
      "        truncate_section(tks, truncate_dir, section_lens[i], add_bos, inplace=inplace)\n",
      "        for i, (tks, truncate_dir) in enumerate(sections)\n",
      "    )\n",
      "\n",
      "class TokenizedEdit(ABC):\n",
      "    input_tks: TokenSeq\n",
      "    output_tks: TokenSeq\n",
      "    main_tks: TokenSeq\n",
      "    path: ProjectPath\n",
      "    change_type: Change[None]\n",
      "\n",
      "    BAD_DELETE = encode_single_line(\"((bad delete))\")\n",
      "\n",
      "    @abstractmethod\n",
      "    def all_ctxs(self) -> dict[str, TokenSeq]:\n",
      "        pass\n",
      "\n",
      "    def meta_data_lines(self) -> list[str]:\n",
      "        return [f\"path: {str(self.path)}\"]\n",
      "\n",
      "    def stats(self) -> Mapping[str, int | float]:\n",
      "        return {\n",
      "            \"input_tks\": len(self.input_tks),\n",
      "            \"output_tks\": len(self.output_tks),\n",
      "            \"main_tks\": len(self.main_tks),\n",
      "        }\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        return f\"{type(self).__name__}(path={str(self.path)}, type={type(self.change_type).__name__}, len(input_tks)={len(self.input_tks)}, len(output_tks)={len(self.output_tks)})\"\n",
      "\n",
      "    @classmethod\n",
      "    def show_label(cls, i: int):\n",
      "        return f\" <{i}>\" if i <= 9 else f\"<{i}>\"\n",
      "\n",
      "    @classmethod\n",
      "    def show_line(cls, tks: TokenSeq):\n",
      "        if tks and tks[0] == Add_id:\n",
      "            return \"+ \" + decode_tokens(tks[1:])\n",
      "        elif tks and tks[0] == Del_id:\n",
      "            return \"- \" + decode_tokens(tks[1:])\n",
      "        else:\n",
      "            return \"  \" + decode_tokens(tks)\n",
      "\n",
      "    @classmethod\n",
      "    def show_predictions(\n",
      "        cls, pred: TokenSeq, main_tk_lines: dict[Token, TokenSeq]\n",
      "    ) -> str:\n",
      "        id_map = {k: i for i, k in enumerate(main_tk_lines)}\n",
      "        segs = output_ids_as_seqs(pred)\n",
      "        lines = []\n",
      "        for k, seg in segs.items():\n",
      "            if not seg:\n",
      "                continue  # skip empty lines\n",
      "            if seg[-1] == Del_id:\n",
      "                # show the deleted line\n",
      "                section_lines = tk_splitlines(main_tk_lines.get(k, TokenSeq()))\n",
      "                if section_lines:\n",
      "                    origin_line = section_lines[0]\n",
      "                else:\n",
      "                    origin_line = cls.BAD_DELETE\n",
      "<extra_id_0>\n",
      "            label = cls.show_label(id_map.get(k, -1))\n",
      "            lines.append(f\"{label}:{indent(decode_tokens(seg),'' * 4).lstrip()}\")\n",
      "        return \"\".join(lines)\n",
      "\n",
      "    def show(self, pred_tks: TokenSeq | None = None, skip_ctx: bool = False) -> str:\n",
      "        def show_ctx(ctx_tks: TokenSeq):\n",
      "            lines = tk_splitlines(ctx_tks)\n",
      "            return \"\\n\".join(\"  \" + self.show_line(l) for l in lines)\n",
      "\n",
      "        main_segs = output_ids_as_seqs(self.main_tks)\n",
      "        id_map = {k: i for i, k in enumerate(main_segs)}\n",
      "        main_lines = list[str]()\n",
      "        for line_tks in tk_splitlines(self.main_tks):\n",
      "            if line_tks and is_extra_id(line_tks[0]):\n",
      "                prefix = self.show_label(id_map.get(line_tks[0], -1))\n",
      "                line = prefix + self.show_line(line_tks[1:])\n",
      "            else:\n",
      "                line = \"    \" + self.show_line(line_tks)\n",
      "            main_lines.append(line)\n",
      "\n",
      "        pred_lines = (\n",
      "            [\n",
      "                \"========Prediction========\",\n",
      "                f\"{self.show_predictions(pred_tks, main_segs)}\",\n",
      "            ]\n",
      "            if pred_tks\n",
      "            else []\n",
      "        )\n",
      "        outputs = [\n",
      "            \"-\" * 80,\n",
      "            *self.meta_data_lines(),\n",
      "            \"========Ground Truth========\",\n",
      "            self.show_predictions(self.output_tks, main_segs),\n",
      "            *pred_lines,\n",
      "            \"========Main Code========\",\n",
      "            \"\\n\".join(main_lines),\n",
      "        ]\n",
      "        if not skip_ctx:\n",
      "            outputs.extend(\n",
      "                f\"==========={name}===========\\n\" + show_ctx(tks)\n",
      "                for name, tks in self.all_ctxs().items()\n",
      "            )\n",
      "        return \"\\n\".join(outputs)\n",
      "\n",
      "\n",
      "    # turn off redundant BLEU warnings\n",
      "    warnings.simplefilter(\n",
      "        \"ignore\",\n",
      "        category=UserWarning,\n",
      "        lineno=552,\n",
      "    )\n",
      "\n",
      "    def is_repetitive_edit(self, blue_threshold=0.8) -> bool:\n",
      "        \"\"\"Check if all additions in the output_tokens can be matched to\n",
      "        an addition in the input_tokens with a BLEU score above the threshold.\"\"\"\n",
      "\n",
      "        def get_changes(tks, key_tk: Token):\n",
      "            if tks and tks[0] == key_tk:\n",
      "                s = decode_tokens(tks[1:])\n",
      "                s.strip()\n",
      "                return encode_single_line(s)\n",
      "            else:\n",
      "                return []\n",
      "\n",
      "        ctx_lines = tk_splitlines(self.input_tks)\n",
      "        main_lines = output_ids_as_seqs(self.input_tks)\n",
      "        ctx_addtions = [tks for l in ctx_lines if (tks := get_changes(l, Add_id))]\n",
      "        ctx_deletions = [tks for l in ctx_lines if (tks := get_changes(l, Del_id))]\n",
      "\n",
      "        def has_match(line, line_key: Token):\n",
      "            if line:\n",
      "                if line[0] == Add_id:\n",
      "                    added = line[1:]\n",
      "                    return any(\n",
      "                        as_any(sentence_bleu([ref], added)) > blue_threshold\n",
      "                        for ref in ctx_addtions\n",
      "                    )\n",
      "                elif line == [Del_id]:\n",
      "                    if line_key not in main_lines:\n",
      "                        print(f\"Key {decode_tokens([line_key])} not found.\")\n",
      "                        print(\"Main tokens:\")\n",
      "                        print(decode_tokens(self.main_tks))\n",
      "                    deleted = main_lines[line_key]\n",
      "                    return any(\n",
      "                        as_any(sentence_bleu([ref], deleted)) > blue_threshold\n",
      "                        for ref in ctx_deletions\n",
      "                    )\n",
      "                else:\n",
      "                    raise ValueError(f\"Unexpected line: {decode_tokens(line)}\")\n",
      "            else:\n",
      "                return True\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "from coeditor.encoding import decode_tokens\n",
    "\n",
    "\n",
    "ex_id = 3\n",
    "input, output = fim_problems[ex_id].to_codet5_format()\n",
    "\n",
    "# we use decode_tokens to convert the token sequences into strings\n",
    "print_sections(\n",
    "    (\"output\", decode_tokens(output)),\n",
    "    (\"input\", decode_tokens(input)),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare this with a different format that models this problem as a special case of code editing. To do that, we will run `edits_from_commit_history` again but with `C3ProblemGenerator` as the `change_processor`. This will give us `C3Problem` instances, which correspond to general contextual code change prediction problem. We can then convert them into instances that are similar to  similar to the `FIMProblem` problems above using `C3ToCodeCompletion`.  will then convert into  we then convert them into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building initial project: 100%|██████████| 34/34 [00:00<00:00, 152.32it/s]\n",
      "processing commits: 100%|██████████| 3/3 [00:09<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(comp_probs) = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from coeditor.c3problem import C3ProblemGenerator, C3ToCodeCompletion\n",
    "\n",
    "c3_problems = edits_from_commit_history(\n",
    "    repo_root, commits, workdir, change_processor=C3ProblemGenerator()\n",
    ")\n",
    "\n",
    "transform = C3ToCodeCompletion()\n",
    "comp_probs = join_list([transform.transform(p) for p in c3_problems])\n",
    "print(f\"{len(comp_probs) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "path: scripts.train_model/train_model\n",
      "n_references: 4\n",
      "total_reference_tks: 1644\n",
      "project: temp-1\n",
      "commit: CommitInfo(hash='a1e2b73ab836924d0b1f9ed88e4fd90e7a6f61e6', parents=('ecdbdc3875e47887ff3c0320fd1367af28d0a491',), msg='Implement ablation: current_code_only.')\n",
      "========Ground Truth========\n",
      " <0>:<add>     eval_tkn.max_query_tks = 1024\n",
      "\n",
      "========Main Code========\n",
      "      <s>train_model\n",
      "      def train_model(\n",
      "          model_name: str,\n",
      "          dataset_name: str,\n",
      "          description: str,\n",
      "          encoder: C3CombinedEncoder = C3CombinedEncoder(),\n",
      "          batch_args=BatchArgs.train_default(),\n",
      "          eval_batch_args=BatchArgs.eval_default(),\n",
      "          train_args=TrainingArgs(),\n",
      "          recreate_data: bool = False,\n",
      "          resumed_from: Path | None = None,\n",
      "          eval_only: bool = False,\n",
      "          quicktest: bool = False,\n",
      "      ):\n",
      "      <s>_from is None:\n",
      "              model = RetrievalEditorModel.from_code_t5(\"base\", reuse_embed=True)\n",
      "          else:\n",
      "              model = RetrievalEditorModel.load(resumed_from)\n",
      "      \n",
      "          if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
      "              warnings.warn(\n",
      "                  \"CUDA_VISIBLE_DEVICES not set, using 0. Note that \"\n",
      "                  \"the Huggingface Trainer will use all visible GPUs for training.\"\n",
      "              )\n",
      "              os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
      "      \n",
      "          train_tkn = encoder.edit_tokenizer\n",
      "          eval_tkn = copy.deepcopy(train_tkn)\n",
      "    -     eval_tkn.max_query_tks *= 2\n",
      " <0>      eval_tkn.max_output_tks *= 2\n",
      "          eval_tkn.max_ref_tks_sum *= 2\n",
      "      \n",
      "          valid_loader = C3DataLoader(\n",
      "              datasets[\"valid\"], None, eval_tkn, eval_batch_args, shuffle=False, desc=\"eval\"\n",
      "          )\n",
      "      \n",
      "          if not eval_only:\n",
      "              # gradually increase the ctx size during training\n",
      "              scales = [4, 2, 1]\n",
      "              for scale in scales:\n",
      "                  s_tkn = copy.copy(train_tkn)\n",
      "                  s_tkn.max_ref_tks_sum //= scale\n",
      "                  s_probs = [\n",
      "                      x\n",
      "                      for x in datasets[\"train\"]\n",
      "                      if sum(c.change_size() for c in x.relevant_changes)\n",
      "                      < s_tkn.max_ref_</s>\n",
      "===========above chunk 0===========\n",
      "    <s>_model(\n",
      "        model_name: str,\n",
      "        dataset_name: str,\n",
      "        description: str,\n",
      "        encoder: C3CombinedEncoder = C3CombinedEncoder(),\n",
      "        batch_args=BatchArgs.train_default(),\n",
      "        eval_batch_args=BatchArgs.eval_default(),\n",
      "        train_args=TrainingArgs(),\n",
      "        recreate_data: bool = False,\n",
      "        resumed_from: Path | None = None,\n",
      "        eval_only: bool = False,\n",
      "        quicktest: bool = False,\n",
      "    ):\n",
      "    # offset: -1\n",
      "    <s> datasets,\n",
      "                encoder,\n",
      "                remake_problems=recreate_data,\n",
      "                workers=multiprocessing.cpu_count(),\n",
      "            )\n",
      "    \n",
      "        # limit the number of examples for faster testing\n",
      "        datasets[\"valid\"] = random_subset(eval_probs[\"valid\"], 10000, rng=42)\n",
      "        datasets[\"test\"] = random_subset(eval_probs[\"test\"], 10000, rng=42)\n",
      "    \n",
      "        config_dict = {\n",
      "            k: get_modified_args(v)\n",
      "            for k, v in {\n",
      "                \"description\": description,\n",
      "                \"edit_tokenizer\": encoder.edit_tokenizer.get_args(),\n",
      "                \"batch_args\": batch_args,\n",
      "                \"train_args\": train_args,\n",
      "                \"dec_args\": dec_args,\n",
      "            }.items()\n",
      "        }\n",
      "    \n",
      "        project = \"Coeditor\" if not quicktest else \"Coeditor-quicktest\"\n",
      "        if eval_only:\n",
      "            project = \"eval-\" + project\n",
      "        wandb.init(dir=\"..\", project=project, name=model_name, config=config_dict)\n",
      "    \n",
      "        if quicktest:\n",
      "            print(\"Using fewer data for quick test.\")\n",
      "            n_quick_exs = 20\n",
      "            datasets = C3ProblemDataset(\n",
      "                train=datasets[\"train\"][:n_quick_exs],\n",
      "                valid=datasets[\"valid\"][:n_quick_exs],\n",
      "                test=datasets[\"test\"][:n_quick_exs],\n",
      "            )\n",
      "    \n",
      "        if resumed_from is None:\n",
      "            model = RetrievalEditorModel.from_code_t5(\"base\", reuse_embed=True)\n",
      "    </s>\n",
      "===========above chunk 1===========\n",
      "    <s>_model(\n",
      "        model_name: str,\n",
      "        dataset_name: str,\n",
      "        description: str,\n",
      "        encoder: C3CombinedEncoder = C3CombinedEncoder(),\n",
      "        batch_args=BatchArgs.train_default(),\n",
      "        eval_batch_args=BatchArgs.eval_default(),\n",
      "        train_args=TrainingArgs(),\n",
      "        recreate_data: bool = False,\n",
      "        resumed_from: Path | None = None,\n",
      "        eval_only: bool = False,\n",
      "        quicktest: bool = False,\n",
      "    ):\n",
      "    # offset: -2\n",
      "        dec_args = DecodingArgs()\n",
      "        if quicktest:\n",
      "            model_name = \"quicktest-\" + model_name\n",
      "    \n",
      "        if not eval_only:\n",
      "            check_save_dir(model_name)\n",
      "    \n",
      "        # problems will be transformed and saved for valid and test but not train.\n",
      "        datasets = make_or_load_dataset(\n",
      "            dataset_name,\n",
      "            encoder.change_processor,\n",
      "            remake_problems=recreate_data,\n",
      "            workers=multiprocessing.cpu_count(),\n",
      "        )\n",
      "    \n",
      "        with timed_action(\"Making or loading transformed C3 problems for eval\"):\n",
      "            # it's important to cache these due to randomness in the transformations\n",
      "            eval_probs = make_or_load_transformed_dataset(\n",
      "                dataset_name,\n",
      "                datasets,\n",
      "                encoder,\n",
      "                remake_problems=recreate_data,\n",
      "                workers=multiprocessing.cpu_count(),</s>\n",
      "===========below chunk 0===========\n",
      "    <s> train_model(\n",
      "        model_name: str,\n",
      "        dataset_name: str,\n",
      "        description: str,\n",
      "        encoder: C3CombinedEncoder = C3CombinedEncoder(),\n",
      "        batch_args=BatchArgs.train_default(),\n",
      "        eval_batch_args=BatchArgs.eval_default(),\n",
      "        train_args=TrainingArgs(),\n",
      "        recreate_data: bool = False,\n",
      "        resumed_from: Path | None = None,\n",
      "        eval_only: bool = False,\n",
      "        quicktest: bool = False,\n",
      "    ):\n",
      "    # offset: 1\n",
      "    <s> if sum(c.change_size() for c in x.relevant_changes)\n",
      "                    < s_tkn.max_ref_tks_sum\n",
      "                ]\n",
      "                n_probs = max(1, len(s_probs) // max(scales) // 2) * scale\n",
      "                s_probs = random_subset(s_probs, n_probs)\n",
      "                desc = f\"training (ctx={s_tkn.max_ref_tks_sum})\"\n",
      "                s_loader = C3DataLoader(\n",
      "                    s_probs,\n",
      "                    encoder.problem_tranform,\n",
      "                    s_tkn,\n",
      "                    batch_args,\n",
      "                    shuffle=True,\n",
      "                    desc=desc,\n",
      "                )\n",
      "    \n",
      "                with timed_action(desc):\n",
      "                    model.train_on_data(model_name, s_loader, valid_loader, train_args)\n",
      "    \n",
      "        model.to(\"cuda\")\n",
      "        test_loader = C3DataLoader(\n",
      "            datasets[\"test\"], None, eval_tkn, eval_batch_args, shuffle=False, desc=\"test\"\n",
      "        )\n",
      "        print(f\"{len(test_loader)}\")\n",
      "        print(f\"{len(test_loader.all_probs)}\")\n",
      "        with timed_action(\"Loss Evaluation\"):\n",
      "            eval_result = model.eval_loss_on_loader(test_loader)\n",
      "            eval_dict = {f\"test/{k}\": v.average() for k, v in eval_result.items()}\n",
      "            wandb.log(eval_dict)\n",
      "    \n",
      "        with timed_action(\"Accuracy Evaluation\"):\n",
      "            out_dir = get_model_dir() / model_name / \"exact</s>\n",
      "===========below chunk 1===========\n",
      "    <s> train_model(\n",
      "        model_name: str,\n",
      "        dataset_name: str,\n",
      "        description: str,\n",
      "        encoder: C3CombinedEncoder = C3CombinedEncoder(),\n",
      "        batch_args=BatchArgs.train_default(),\n",
      "        eval_batch_args=BatchArgs.eval_default(),\n",
      "        train_args=TrainingArgs(),\n",
      "        recreate_data: bool = False,\n",
      "        resumed_from: Path | None = None,\n",
      "        eval_only: bool = False,\n",
      "        quicktest: bool = False,\n",
      "    ):\n",
      "    # offset: 2\n",
      "    <s>    with timed_action(\"Accuracy Evaluation\"):\n",
      "            out_dir = get_model_dir() / model_name / \"exact_match_samples\"\n",
      "            exact_acc = model.eval_on_data(\n",
      "                datasets[\"test\"],\n",
      "                test_loader,\n",
      "                dec_args,\n",
      "                out_dir,\n",
      "                probs_to_save=300,\n",
      "            )\n",
      "            print(\"Exact-match accuracy:\", exact_acc)\n",
      "            wandb.log({\"test/exact-acc\": exact_acc.average()})\n",
      "            cprint(\"blue\", \"Exact-match samples saved to:\", out_dir)\n",
      "    \n",
      "        return model\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from coeditor.c3problem import C3ProblemTokenizer\n",
    "\n",
    "\n",
    "tknizer = C3ProblemTokenizer(max_ref_tks_sum=2000)\n",
    "print(tknizer.tokenize_problem(comp_probs[ex_id]).show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
