{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pmap: _process_commits: 100%|██████████| 50/50 [08:51<00:00, 10.62s/repo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing workdir: /tmp/dataset_from_projects/pid-29537\n",
      "Time stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_time</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post_edit_analysis</td>\n",
       "      <td>16207</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>645.882481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>checkout</td>\n",
       "      <td>48671</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>455.286273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parse_module</td>\n",
       "      <td>28126</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>281.389130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>process_change</td>\n",
       "      <td>16207</td>\n",
       "      <td>0.014285</td>\n",
       "      <td>231.519041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JModuleChange.from_modules</td>\n",
       "      <td>29669</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>86.535892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre_edit_analysis</td>\n",
       "      <td>16207</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.029807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  count  avg_time  total_time\n",
       "3          post_edit_analysis  16207  0.039852  645.882481\n",
       "0                    checkout  48671  0.009354  455.286273\n",
       "1                parse_module  28126  0.010005  281.389130\n",
       "5              process_change  16207  0.014285  231.519041\n",
       "2  JModuleChange.from_modules  29669  0.002917   86.535892\n",
       "4           pre_edit_analysis  16207  0.000002    0.029807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset total size (n=50): 126.45 MB\n",
      "len(fim_probs) = 17757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pmap: _process_commits: 100%|██████████| 50/50 [00:05<00:00,  9.17repo/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset total size (n=1649): 5150.76 MB\n",
      "len(c3_probs) = 17744\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from numpy import mean\n",
    "\n",
    "from coeditor.c3problem import (\n",
    "    C3ProblemGenerator,\n",
    "    C3ProblemTokenizer,\n",
    "    C3ToCodeCompletion,\n",
    "    CompletionKind,\n",
    ")\n",
    "\n",
    "from coeditor.common import *\n",
    "from coeditor.dataset import make_or_load_dataset\n",
    "from coeditor.encoding import inline_output_tokens, tokens_to_change\n",
    "from coeditor.experiments.code_completion import (\n",
    "    C3CompletionGenerator,\n",
    "    CodeT5Wrapper,\n",
    "    FIMModel,\n",
    "    infill_with_coeditor,\n",
    ")\n",
    "from coeditor.experiments.in_coder import InCoderWrapper\n",
    "from coeditor.experiments.santa_coder import SantaCoderWrapper\n",
    "from coeditor.model import RetrievalEditorModel\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "dataset_name = \"perm2k\"\n",
    "device = \"cuda\"\n",
    "N_test = 5000\n",
    "use_additions = True\n",
    "use_modifications = True\n",
    "\n",
    "# first, load the test data, in FIM format\n",
    "fim_probs = make_or_load_dataset(\n",
    "    dataset_name,\n",
    "    C3CompletionGenerator(\n",
    "        use_additions=use_additions, use_modifications=use_modifications\n",
    "    ),\n",
    "    splits=(\"test\",),\n",
    "    time_limit_per_commit=30,\n",
    "    remake_problems=False,\n",
    ")[\"test\"]\n",
    "print(f\"{len(fim_probs) = }\")\n",
    "\n",
    "# and in C3 format\n",
    "c3_probs = make_or_load_dataset(\n",
    "    dataset_name,\n",
    "    C3ProblemGenerator(),\n",
    "    splits=(\"test\",),\n",
    "    time_limit_per_commit=40,\n",
    ")[\"test\"]\n",
    "transform = C3ToCodeCompletion(\n",
    "    use_additions=use_additions, use_modifications=use_modifications\n",
    ")\n",
    "c3_probs = join_list(transform.transform(p) for p in c3_probs)\n",
    "print(f\"{len(c3_probs) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(common_ids) = 17738\n"
     ]
    }
   ],
   "source": [
    "# keep only problems that appear in both sets\n",
    "fim_ids = set(p.uid() for p in fim_probs)\n",
    "c3_ids = set(p.uid() for p in c3_probs)\n",
    "common_ids = fim_ids.intersection(c3_ids)\n",
    "print(f\"{len(common_ids) = }\")\n",
    "fim_probs = [p for p in fim_probs if p.uid() in common_ids]\n",
    "fim_probs.sort(key=lambda p: p.uid())\n",
    "c3_probs = [p for p in c3_probs if p.uid() in common_ids]\n",
    "c3_probs.sort(key=lambda p: p.uid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGLMForCausalLM(\n",
       "  (model): XGLMModel(\n",
       "    (embed_tokens): Embedding(50518, 4096, padding_idx=1)\n",
       "    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x XGLMDecoderLayer(\n",
       "        (self_attn): XGLMAttention(\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50518, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeditor = RetrievalEditorModel.load(get_coeditor_model_path())\n",
    "coeditor.half()\n",
    "coeditor.to(device)\n",
    "\n",
    "incoder6B = InCoderWrapper.from_pretrained(\"facebook/incoder-6B\", half_precision=True)\n",
    "incoder6B.model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coeditor.c3problem import C3Problem\n",
    "from coeditor.encoding import decode_tokens\n",
    "from coeditor.experiments.code_completion import FIMProblem\n",
    "import torch\n",
    "\n",
    "tknizer = C3ProblemTokenizer.for_eval()\n",
    "\n",
    "def run_incoder(prob: FIMProblem):\n",
    "    left_ctx = \"\\n\".join(prob.left_ctx) + \"\\n\"\n",
    "    right_ctx = \"\\n\" + \"\\n\".join(prob.right_ctx)\n",
    "    with torch.no_grad():\n",
    "        pred = incoder6B.infill(left_ctx, right_ctx, max_length=128)\n",
    "    if pred:\n",
    "        pred = pred.split(\"\\n\")[0]  # only keep the first predicted line\n",
    "    left_part = prob.left_ctx[-1] + \"\\n\" if prob.left_ctx else \"\"\n",
    "    right_part = \"\\n\" + prob.right_ctx[0] if prob.right_ctx else \"\"\n",
    "    pred_code = left_part + pred + right_part\n",
    "    label_code = left_part + prob.middle + right_part\n",
    "    correct = code_equal(pred_code, label_code)\n",
    "    log = show_sections(\n",
    "        (\"Kind\", prob.kind),\n",
    "        (\"Incoder output\", pred),\n",
    "        (\"Label\", prob.middle),\n",
    "        (\"Left context\", left_ctx),\n",
    "        (\"Right context\", right_ctx),\n",
    "    )\n",
    "    return correct, log\n",
    "\n",
    "def run_coeditor(prob: C3Problem):\n",
    "    tk_prob = tknizer.tokenize_problem(prob)\n",
    "    output = infill_with_coeditor(coeditor, tk_prob)\n",
    "    pred_code = tokens_to_change(inline_output_tokens(tk_prob.main_tks, output)).after\n",
    "    label_code = tokens_to_change(\n",
    "        inline_output_tokens(tk_prob.main_tks, tk_prob.output_tks)\n",
    "    ).after\n",
    "    correct = code_equal(pred_code, label_code)\n",
    "    log = show_sections(\n",
    "        (\"Coeditor output\", f\"{decode_tokens(output)}\"),\n",
    "        (\"Label\", f\"{decode_tokens(tk_prob.output_tks)}\"),\n",
    "        (\"Main context\", f\"{decode_tokens(tk_prob.main_tks)}\")\n",
    "    )\n",
    "    return correct, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(shuff_ids) = 13396\n"
     ]
    }
   ],
   "source": [
    "shuff_ids = [i for i, prob in enumerate(fim_probs) if prob.kind == \"mod\"]\n",
    "random.Random(42).shuffle(shuff_ids)\n",
    "print(f\"{len(shuff_ids) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/13388 [00:10<19:30:13,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/13388 [00:43<17:33:03,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/13388 [00:47<16:54:21,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/13388 [00:52<17:33:30,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/13388 [01:18<18:20:32,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/13388 [01:44<19:37:46,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/13388 [01:49<19:19:53,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/13388 [02:03<17:22:09,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/13388 [02:13<18:08:21,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/13388 [02:32<18:52:09,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cases = []\n",
    "\n",
    "for i in tqdm(range(8, len(shuff_ids))):\n",
    "    ex_id = shuff_ids[i]\n",
    "    fim_prob = fim_probs[ex_id]\n",
    "    c3_prob = c3_probs[ex_id]\n",
    "\n",
    "    coeditor_correct, coeditor_log = run_coeditor(c3_prob)\n",
    "    incoder_correct, incoder_log = run_incoder(fim_prob)\n",
    "    if coeditor_correct and not incoder_correct:\n",
    "        cases.append({\"ex_id\": ex_id, \"coeditor_log\": coeditor_log, \"incoder_log\": incoder_log})\n",
    "        print(f\"{len(cases)} found.\")\n",
    "        if len(cases) >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_id: 929\n",
      "--------------------------------------------------------------------------------\n",
      "Coeditor output:\n",
      "<pad><s><extra_id_0> <add>     return get_async_backend().get_running_tasks()\n",
      "</s>\n",
      "--------------------------------------------------------------------------------\n",
      "Label:\n",
      "<extra_id_0> <add>     return get_async_backend().get_running_tasks()\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Main context:\n",
      "# module: anyio._core._testing\n",
      "def get_running_tasks() -> list[TaskInfo]:\n",
      "    \"\"\"\n",
      "    Return a list of running tasks in the current event loop.\n",
      "\n",
      "    :return: a list of task info objects\n",
      "\n",
      "    \"\"\"\n",
      " <del>     return get_asynclib().get_running_tasks()\n",
      "<extra_id_0>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30201"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_dict = cases[8]\n",
    "print(\"ex_id:\", case_dict[\"ex_id\"])\n",
    "print(case_dict[\"coeditor_log\"])\n",
    "tk_prob = tknizer.tokenize_problem(c3_probs[case_dict[\"ex_id\"]])\n",
    "Path(\"output/coeditor_format.txt\").write_text(tk_prob.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Kind:\n",
      "mod\n",
      "--------------------------------------------------------------------------------\n",
      "Incoder output:\n",
      "    return get_asynclib().get_running_tasks()\n",
      "--------------------------------------------------------------------------------\n",
      "Label:\n",
      "    return get_async_backend().get_running_tasks()\n",
      "--------------------------------------------------------------------------------\n",
      "Left context:\n",
      "# module: anyio._core._testing\n",
      "class TaskInfo:\n",
      "    \"\"\"\n",
      "    Represents an asynchronous task.\n",
      "\n",
      "    :ivar int id: the unique identifier of the task\n",
      "    :ivar parent_id: the identifier of the parent task, if any\n",
      "    :vartype parent_id: Optional[int]\n",
      "    :ivar str name: the description of the task (if any)\n",
      "    :ivar ~collections.abc.Coroutine coro: the coroutine object of the task\n",
      "    \"\"\"\n",
      "\n",
      "    __slots__ = '_name', 'id', 'parent_id', 'name', 'coro'\n",
      "\n",
      "    def __init__(self, id: int, parent_id: int | None, name: str | None,\n",
      "                 coro: Generator[Any, Any, Any] | Awaitable[Any]):\n",
      "        func = get_current_task\n",
      "        self._name = f'{func.__module__}.{func.__qualname__}'\n",
      "        self.id: int = id\n",
      "        self.parent_id: int | None = parent_id\n",
      "        self.name: str | None = name\n",
      "        self.coro: Generator[Any, Any, Any] | Awaitable[Any] = coro\n",
      "\n",
      "    def __eq__(self, other: object) -> bool:\n",
      "        if isinstance(other, TaskInfo):\n",
      "            return self.id == other.id\n",
      "\n",
      "        return NotImplemented\n",
      "\n",
      "    def __hash__(self) -> int:\n",
      "        return hash(self.id)\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        return f'{self.__class__.__name__}(id={self.id!r}, name={self.name!r})'\n",
      "\n",
      "    def _unwrap(self) -> TaskInfo:\n",
      "        return self\n",
      "\n",
      "def get_current_task() -> TaskInfo:\n",
      "    \"\"\"\n",
      "    Return the current task.\n",
      "\n",
      "    :return: a representation of the current task\n",
      "\n",
      "    \"\"\"\n",
      "    return get_async_backend().get_current_task()\n",
      "\n",
      "def get_running_tasks() -> list[TaskInfo]:\n",
      "    \"\"\"\n",
      "    Return a list of running tasks in the current event loop.\n",
      "\n",
      "    :return: a list of task info objects\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Right context:\n",
      "\n",
      " def wait_all_tasks_blocked() -> None:\n",
      "    \"\"\"Wait until all other tasks are waiting for something.\"\"\"\n",
      "    await get_asynclib().wait_all_tasks_blocked()\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(case_dict[\"incoder_log\"])\n",
    "Path(\"output/incoder_log.txt\").write_text(case_dict[\"incoder_log\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
